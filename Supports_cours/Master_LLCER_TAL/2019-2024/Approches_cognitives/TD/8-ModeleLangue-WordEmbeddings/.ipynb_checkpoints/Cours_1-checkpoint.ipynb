{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1MRPhizGhSf"
   },
   "source": [
    "## Les inconvénients de la méthode sac de mots\n",
    "\n",
    "Dans les cours précédents, nous avons utilisé la méthode du sac de mots afin d'encoder des données textuelles afin de pouvoir les donner en entrée à nos algorithmes. Cette méthode à été une des premières utilisée dans le domaine du TAL et du Machine Learning. En encodant chaque token par leur fréquence d'apparition ou par leur poids par rapport aux documents du corpus (Tf-idf), cette méthode permet de constituer des vecteurs de mots, qui sont ensuite utilisés comme données d'entraînement à nos modèles.\n",
    "\n",
    "Cependant, comme nous l'avons déjà vu, cette méthode d'encodage du texte et donc cette méthode de production des vecteurs posent plusieurs problèmes du point de vue informatique et linguistique:\n",
    "\n",
    "* Pour chaque samples de notre dataset, on créé un vecteur dont le nombre de dimensions est égal à la taille de notre vocabulaire. Ces vecteurs sont donc généralement composés de plusieurs dizaines de millier de dimensions, ce qui est très coûteux en terme de calcul.\n",
    "\n",
    "* De plus, pour chaque sample, seuls une très petite portion de notre vocabulaire y est présent. Ainsi, peut importe la méthode d'encodage que l'on choisit, le vecteur de mots sera essentiellement composé de zéros. L'essentielle des dimensions de notre vecteur ne sont donc pas pertinentes pour la compréhension du sample traité.\n",
    "\n",
    "* Le sac de mot ne conserve aucune information sur la structure du texte ni la syntaxe de la phrase. Or, un même vocabulaire peut prendre un sens très différent selon l'ordre dans lequel il est utilisé. \n",
    "\n",
    "* La valeur que prend un mot dépend de son encodage, c'est-à-dire soit de son nombre d'occurrences dans le corpus, soit de son poids par rapport aux autres termes dans le document et dans le corpus. Ainsi, il n'a pas de vraie valeur sémantique.\n",
    "\n",
    "Ainsi il est évident que la méthode sac de mots n'est pas suffisante si l'on souhaite améliorer les modèles existants ou réduire la puissance de calcul demandée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedings\n",
    "\n",
    "Les Words Embeddings sont très différents des sac de mots: Un Word Embeddings peut se comparer à un dictionnaire pour lequel chaque clé est un mot et chaque valeur est un vecteur représentant ce mot. La taille de ces vecteurs est de l'ordre de la centaine, et sont généralement constitués de 50, 100, 300 ou 500 dimensions, ce qui est extrêmement réduit par rapport au vecteur de vocabulaire du sac de mots. \n",
    "\n",
    "Ci-dessous, un exemple de faux Word Embbedings:\n",
    "\n",
    "``\n",
    "we = {\n",
    "    \"chat\": [0.33, 0.5, 0.86, 0.77, 0.23],\n",
    "    \"le\" : [0.21, 1, 0.93, 0.54, 0.64],\n",
    "    \"rat\" : [0.96, 0.16, 0.98, 0.88, 0.26],\n",
    "    \"mange\" : [0.63, 0.97, 0.4, 0.32, 0.43]\n",
    "}\n",
    "``\n",
    "\n",
    "En utilisant la méthode de sac de mots, on encoderait la phrase ``Le chat mange le rat`` avec un vecteur de la taille du vocabulaire et dans lequel on indiquerait la présence (one-hot encoding) oule nombre d'occurrences de chaque mot. A l'inverse en encodant cette phrases avec des Word Embeddings, chaque mot serait représenté par le vecteur qui lui est associé:\n",
    "\n",
    "``[\n",
    "    [0.21, 1, 0.93, 0.54, 0.64], ==> le\n",
    "    [0.33, 0.5, 0.86, 0.77, 0.23], ==> chat\n",
    "    [0.63, 0.97, 0.4, 0.32, 0.43], ==> mange\n",
    "    [0.21, 1, 0.93, 0.54, 0.64], ==> le\n",
    "    [0.96, 0.16, 0.98, 0.88, 0.26] ==> rat\n",
    "]``\n",
    "\n",
    "### Note\n",
    "\n",
    "Le terme Word Embedding fait référence au fait de représenter un mot sous forme de vecteur. Ainsi, un vecteur dans lequel on indique la fréquence d'apparition d'un mot dans un contexte donné ou bien son poids par rapport au corpus est un Word Embedding. Cependant, on distingue ces méthodes de celles où ces vecteurs sont appris de manière automatique et qui comporte une plus grande information sémantique: ce sont ces méthodes (Word2Vec, GloVe, fastText, ...) que l'on englobe communément dans le terme \"Word Embeddings\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Le terme Word Embeddings est réellement devenu proéminent dans le domaine du TAL et du Machine Learning grâce l'algorithme ``Word2Vec``, développé par Mikolov et al (2013). A son apparition, Word2Vec a totalement chamboulé le domaine du TAL: en représentant les mots dans un espace vectorielle, il a permis de traiter l'aspect sémantique d'un vocabulaire. Ainsi, des performances jamais obtenues jusque là ont pu être atteinte, tandis que de nouveaux traitements linguistiques s'ouvraient.\n",
    "\n",
    "<img src='data/img/wordemb.png'>\n",
    "\n",
    "\n",
    "Ref: https://medium.com/@hari4om/word-embedding-d816f643140\n",
    "\n",
    "<img src='data/img/wordemb2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sémantique, logique et mathématique\n",
    "\n",
    "Un intérêt majeur de représenter le vocabulaire sous forme de vecteur est que cela permet de réaliser des opérations logiques au travers d'opérations mathématiques. \n",
    "\n",
    "### Calcul de similarité\n",
    "\n",
    "Tout d'abord, cela permet pour un ou plusieurs mots donnés d'en trouver les plus similaires. Ci-dessous on peut voir que les mots \"cat\" et \"kitten\" sont très proches. Mathématiquement, on peut calculer la similarité entre ces deux vecteurs (donc deux mots) en calculant leur similarité cosinus.\n",
    "\n",
    "<img src='data/img/cat_kitten.png'>\n",
    "\n",
    "### Analogie\n",
    "\n",
    "Un autre aspect très important des Word Embeddings est qu'il permet de traiter l'analogie entre différents termes. Ci-dessous une analogie très célèbre dans le contexte des Word Embeddings:\n",
    "\n",
    "``Le mot 'homme' est au mot 'femme' ce que le mot 'roi' est au mot 'reine``\n",
    "\n",
    "Comme on peut le voir sur l'image ci-dessous, la relation entre les points (man - woman) et (king - queen) sont similaires et situés relativement proches les uns des autres.\n",
    "\n",
    "<img src='data/img/king_queen.png'>\n",
    "\n",
    "\n",
    "Grâce aux vecteurs, on peut exprimer l'analogie ci-dessus de manière mathématique avec des additions et des soustractions:\n",
    "\n",
    "`` (roi - homme) + femme = reine``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW et SkipGram\n",
    "\n",
    "Contrairement aux travaux précédents, qui se basaient sur des matrices de co-occurrences de mots pour générer des vecteurs, Word2Vec consiste à entraîner un réseau de neurones à partir duquel on génère les vecteurs de mots. Le nombre de dimensions des vecteurs produits par cette méthode est de lors d'une à plusieurs centaines, ce qui est considérablement moins que les dizaines de millier de dimensions avec le sac de mots.\n",
    "\n",
    "``Word2Vec`` se divise en deux méthodes opposées d'apprentissage: ``CBOW (Continuous Bag of Words)`` et ``SkipGram``. \n",
    "\n",
    "<img src=\"data/img/cbow_skipgram.png\">\n",
    "\n",
    "\n",
    "* CBOW: le modèle doit prédire un mot en ayant comme donnée d'entrée son contexte direct, qui est constitué d'une fenêtre plus ou moins grande de mots\n",
    "\n",
    "<img src='data/img/bow.gif'>\n",
    "\n",
    "* Skip-gram: Le modèle prend en entrée un mot et doit prédire son contexte. C'est l'opposé de CBOW.\n",
    "\n",
    "<img src='data/img/skip.gif'>\n",
    "\n",
    "\n",
    "Lors de l'entraînement, le modèle apprend des paramètres de manière itérative qui lui permette de prédire (correctement ou non) les mots cibles. Ce sont ces paramètres qui vont constituer les vecteus de mots, et ainsi, ce sont ces paramètres et pas tant le modèle en lui-même que l'on va conserver.\n",
    "\n",
    "### Avantages et inconvénients de chaque méthode\n",
    "\n",
    "* Skip-gram est plus adapté aux petits corpus. De plus, elle représente mieux les mots relativement peu fréquents dans le corpus. Cependant, son temps d'entraînement est très long.\n",
    "* CBOW est plus adapté aux grands corpus. Il généralise mieux que Skip-gram, et représente donc mieux les mots plutôts fréquents. De plus, il est relativement rapide à entraîner. Cependant, il peut donner de mauvais résultats sur un corpus trop petit et les poids obtenus ne seront pas autant spécialisés qu'avec Skip-gram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner votre propre modèle\n",
    "\n",
    "### Charger les données\n",
    "\n",
    "Nous allons entraîner notre premier modèle sur la portion d'analyse de sentiments du ``amazon_reviews`` que nous avons sauvegardé précédemment. Cette portion se trouve dans le dossier ``data/multiclass`` de ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A déconseiller - Article n'a fonctionné qu'une...\n",
       "1    Si vous voulez être déçu achetez le produit ! ...\n",
       "2    Écran de mauvaise qualité, car il s'use en peu...\n",
       "3    Cet engin ne sert à rien les sons sont pourris...\n",
       "4    Très beau produit mais la grue n'a pas fonctio...\n",
       "Name: texts, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/multiclass/as_train.csv')\n",
    "texts = df.texts\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim attend que les données d'entrées soit au minimum tokenizées. Pour l'exemple ci-dessous, nous nous contenterons de diviser les phrases au niveau des espaces, mais il est recommandé de prétraiter vos données de la même manière que précédemment, c'est à dire d'utiliser un vrai tokenizer, de supprimer les mots-vides, de transformer le texte en minuscule, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['déconseiller',\n",
       " '-',\n",
       " 'article',\n",
       " \"n'a\",\n",
       " 'fonctionné',\n",
       " \"qu'une\",\n",
       " '-',\n",
       " 'recommande',\n",
       " 'produit',\n",
       " '-',\n",
       " \"l'ai\",\n",
       " 'jeté',\n",
       " '...']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/fr_stopwords.txt') as f:\n",
    "    stopwords = [line.strip() for line in f]\n",
    "\n",
    "def tokenize(data):\n",
    "    \"\"\"\n",
    "    Simple tokenizer pour l'exemple\n",
    "    \"\"\"\n",
    "    new_data = [text.lower() for text in data]\n",
    "    new_data = [text.split() for text in new_data] # tokenize\n",
    "    new_data = [[word for word in doc if word not in stopwords]\n",
    "               for doc in new_data]\n",
    "    return new_data\n",
    "\n",
    "train = tokenize(texts)\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "\n",
    "``scikit-learn`` ne permet pas d'utiliser ou d'entraîner des Words Embeddings. Pour cela, nous allons utiliser ``gensim``, une librairie de TAL spécialisée dans les tâches non-supervisées (topic modelling, word embeddings, ...). \n",
    "\n",
    "Elle propose également une implémentation de Word2Vec ainsi que d'autres algorithmes similaires tels que GloVe et FastText (que nous présenterons plus tard). Elle sert également d'API permettant d'utiliser ces trois algorithmes de la même manière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec # on importe la classe Word2Vec\n",
    "# crééer le modèle et lui donner les données lance l'entraînement\n",
    "model = Word2Vec(sentences = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, le modèle Word2Vec de Gensim créé des vecteurs à 100 dimensions et utilise la méthode CBOW. De plus, il ne considère par défaut que les mots occurrants au moins 5 fois dans le corpus et utilie une fenêtre de 5 mots de contexte lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 déconseiller\n",
      "1 -\n",
      "2 article\n",
      "3 n'a\n",
      "4 fonctionné\n",
      "5 qu'une\n",
      "6 recommande\n",
      "7 produit\n",
      "8 l'ai\n",
      "9 jeté\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(i, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans Gensim, les vecteurs sont contenus dans la propriété ``wv`` de votre modèle. Pour obtenir l vecteur d'un mot, il suffit de le donner en index, comme pour un dictionnaire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45888647, -0.2234245 ,  1.0588118 ,  0.17715554, -2.0031192 ,\n",
       "       -0.5204801 ,  1.396734  ,  0.91427624, -0.36203417,  0.34283996,\n",
       "        0.3836442 ,  0.16290967, -0.08913777,  2.2415888 , -2.464358  ,\n",
       "        1.0400678 , -0.37535676,  0.13953882,  1.5094519 ,  1.0292692 ,\n",
       "        1.3528557 ,  0.77755046,  0.8345684 , -0.23912643,  0.6121547 ,\n",
       "       -1.2456261 , -0.15046148,  0.46365762,  0.8176515 , -0.6017635 ,\n",
       "        0.12337676,  0.45682794, -0.5417589 ,  1.2351259 ,  1.4328978 ,\n",
       "       -0.73763585, -0.18944754,  0.70769125,  0.64544696,  0.8238502 ,\n",
       "       -0.00873971,  0.51402414, -0.9685393 , -0.75301147,  1.110894  ,\n",
       "        0.83039474, -0.30357382,  1.5298254 ,  0.13529146, -1.4710963 ,\n",
       "       -2.7924285 , -0.6263358 ,  0.22374752, -0.05875881,  0.60461795,\n",
       "        0.85632   ,  0.0060718 ,  1.3014207 ,  1.2755917 ,  1.2385944 ,\n",
       "       -1.6006093 , -2.227908  , -0.6053225 ,  1.9376652 , -1.1466837 ,\n",
       "       -1.4001453 , -1.3310372 ,  0.8199121 ,  0.05051531,  1.1128341 ,\n",
       "       -1.3033361 , -0.47678697,  1.2892973 , -1.1241739 ,  1.0721252 ,\n",
       "        0.49505723, -1.0294425 ,  0.53590596,  0.74147016, -0.69749343,\n",
       "        0.3402068 , -0.15556285, -0.2904669 ,  0.3413724 , -0.25286224,\n",
       "       -0.75129265,  0.5037711 ,  0.46806574, -1.0496973 , -0.64854574,\n",
       "        0.89488786,  1.1133662 ,  2.3171005 ,  0.49152645, -0.2757608 ,\n",
       "        2.0597718 , -0.47793102, -1.2361201 ,  0.38749176, -1.3527994 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver le mot le plus similaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('produit', 0.8346537351608276),\n",
       " (\"l'article\", 0.7938840389251709),\n",
       " ('article,', 0.7445089817047119),\n",
       " ('objet', 0.7073832750320435),\n",
       " ('article.', 0.6887216567993164),\n",
       " ('l’article', 0.6817178726196289),\n",
       " (\"l'article.\", 0.663048505783081),\n",
       " ('produit,', 0.6384209394454956),\n",
       " (\"l'article,\", 0.6302312016487122),\n",
       " ('marchandise', 0.6267038583755493)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la similarité entre deux mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 'article' - 'produit' : 0.1653462052345276\n",
      "Distance 'article' - 'canard' : 0.8274348974227905\n"
     ]
    }
   ],
   "source": [
    "print(\"Distance 'article' - 'produit' :\", model.wv.distance('article', 'produit'))\n",
    "print(\"Distance 'article' - 'canard' :\", model.wv.distance('article', 'canard'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la similarité entre deux vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance 'article' - 'produit' : [0.8346538]\n",
      "Distance 'article' - 'canard' : [0.1725651]\n"
     ]
    }
   ],
   "source": [
    "article = model.wv['article']\n",
    "produit = model.wv['produit']\n",
    "canard = model.wv['canard']\n",
    "\n",
    "print(\"Distance 'article' - 'produit' :\", model.wv.cosine_similarities(article, [produit]))\n",
    "print(\"Distance 'article' - 'canard' :\", model.wv.cosine_similarities(article, [canard]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifier les mots les plus similaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('produit', 0.8346537351608276),\n",
       " (\"l'article\", 0.7938840389251709),\n",
       " ('article,', 0.7445089817047119),\n",
       " ('objet', 0.7073832750320435),\n",
       " ('article.', 0.6887216567993164),\n",
       " ('l’article', 0.6817178726196289),\n",
       " (\"l'article.\", 0.663048505783081),\n",
       " ('produit,', 0.6384209394454956),\n",
       " (\"l'article,\", 0.6302312016487122),\n",
       " ('marchandise', 0.6267038583755493)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifie les mots les plus similaire d'un mot\n",
    "model.wv.similar_by_word('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produit'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifie le mot le plus similaires de la liste par rapport\n",
    "# a un autre mot\n",
    "list_word = ['produit', 'canard', 'roi']\n",
    "model.wv.most_similar_to_given('article', list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article', 0.7674753665924072),\n",
       " ('matériel', 0.7056542634963989),\n",
       " ('produit,', 0.6918157339096069),\n",
       " ('article,', 0.6690899133682251),\n",
       " (\"l'article\", 0.6573989391326904),\n",
       " (\"l'objet\", 0.6359235048294067),\n",
       " ('produits', 0.6223973631858826),\n",
       " ('produit.', 0.6144270896911621),\n",
       " ('site.', 0.602782130241394),\n",
       " ('packaging', 0.5844517946243286)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifie les mots les plus similaires en se basant sur deux listes:\n",
    "# une liste positive et une liste négative\n",
    "# retourne les mots les plus similaires à un champ lexical donné par la liste positive\n",
    "# en faisant en sorte de s'éloigner du champ lexical des mots négatifs\n",
    "pos = ['objet', 'produit']\n",
    "neg = ['chien']\n",
    "model.wv.most_similar(pos, neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifier un intrus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'canard'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_word = ['article', 'objet', 'produit', 'canard']\n",
    "model.wv.doesnt_match(list_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifier un mot plus proche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['produit', \"l'article\", 'article,']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.words_closer_than('article', 'objet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder le modèle sur le disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "savepath = 'data/w2v_model'\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "wv_model.save(f\"{savepath}/amazon_vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser des Word Embeddings\n",
    "\n",
    "L'entraînement d'un modèle comme Word2Vec étant non-supervisé, il peut être utile de visualiser les résultats pour se rendre compte de la qualité. Cependant, les Word Embeddings ont certes bien moins de dimensions que les sacs de mots, il n'en reste pas moins qu'ils en comportent souvent plusieurs centaines. \n",
    "\n",
    "Ainsi, pour les visualiser, il est nécessaire de réduire le nombre de dimensions sans que cela n'en change la valeur. Pour cela, on peut faire appel à des techniques de réduction de dimensions telles que PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-8d529525dddb>:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  X = model[model.wv.vocab]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32528, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "results = pca.fit_transform(X)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df = pd.DataFrame(results, columns=['x', 'y'], index = model.wv.vocab)\n",
    "data = df.iloc[:25]\n",
    "\n",
    "data.plot('x', 'y', kind='scatter', ax=ax)\n",
    "\n",
    "for k, v in data.iterrows():\n",
    "    ax.annotate(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres méthodes de Word Embeddings\n",
    "\n",
    "### GloVe\n",
    "\n",
    "GloVe est un algorithme créé par Penington et al en 2014 faisant suite à Word2Vec tout en étant très différent. Pour un corpus donné, GloVe constitue un vocabulaire ainsi qu'une liste de contexte. Il calcule ensuite la matrice de co-occurrences entre chaque mot du vocabulaire et un contexte donné. La taille du vocabulaire ainsi que des contextes possibles produisent une matrice gigantesque: GloVe utilise donc ensuite différentes méthodes pour réduire le nombre de dimensions de cette matrice, tout en conservant les informations produites.\n",
    "\n",
    "Ainsi, GloVe se distingue de Word2Vec par deux aspects: tout d'abord il repose sur des méthodes statistiques et sur des matrices de co-occurrences plutôt que sur l'entraînement d'un réseau de neurones, et enfin les vecteurs produits ne sont pas de simple vecteurs one-hot, mais des vecteurs de co-occurrences mots-contexte, qui comportent beaucoup plus de valeur sémantique. Contrairement à Word2Vec, GloVe produit une matrice de co-occurrences pour l'ensemble du corpus, tandis que Word2Vec ne traite le contexte que sur une fenêtre donnée. Bien que produire cette matrice peut prendre du temps, l'opération n'est réalisée qu'une seule fois, contrairement à Word2Vec.\n",
    "\n",
    "En cela, la méthode GloVe produit de meilleurs Word Embeddings et ce plus rapidement.\n",
    "\n",
    "### Exemple de matrice de co-occurrences de mots\n",
    "\n",
    "Ref : https://www.linkedin.com/pulse/word2vec-co-occurrence-words-shamane-siriwardhana/\n",
    "\n",
    "<img src='data/img/coocc_matrix.jpeg'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fastText\n",
    "\n",
    "Bien que Word2Vec et GloVe permettent de produire d'excellents Word Embeddings, ils ont en commun un défaut majeur: ils ne peuvent produire ou donner un vecteur d'un mot qui n'est pas contenu dans leur vocabulaire. En effet lors de l'entraînement, ces deux modèles constituent un vocabulaire pour lequel ils calculent les vecteurs associés à chaque mot. Cependant, si l'on devait utiliser un Word Embeddings produit de cette façon sur un corpus comportant de nouveaux mots, on ne pourrait obtenir les vecteurs pour ces mots: il faudra donc les ignorer. \n",
    "\n",
    "FastText est un algorithme produit par FAIR (Facebook's AI Research) en réponse à cette problématique en 2015. Il repose sur la même méthode que Word2Vec (plus précisémment la méthode Skip-gram). Cependant, contrairement à Word2Vec et GloVe, il ne constitue pas un vocabulaire par unité lexicale mais par sous-unités. Ainsi, au moment de produire le vecteur d'un mot, fastText produit déjà les vecteurs associés à chaque sous-unité composant ce nom, puis les combine. Ainsi pour chaque mot inconnu dans un nouveau corpus, fastText en produira un vecteur en le décomposant automatiquement en sous-unité qu'il connaît. \n",
    "\n",
    "### Exemple des sous-unités lexicales\n",
    "\n",
    "Ref : https://amitness.com/2020/06/fasttext-embeddings/\n",
    "\n",
    "<img src='data/img/fasttext.png'>\n",
    "\n",
    "Un autre avantage énorme de fastText est que l'équipe de FAIR a déjà traité près de 300 langues différentes et a produit des Word Embedding pour chaque d'elle. Ceci vous permet donc d'accéder facilement aux Word Embeddings et de les incorporer à votre projet.\n",
    "\n",
    "## Autres algorithmes de Word Embeddings\n",
    "\n",
    "* ELMo\n",
    "* Pointcare Embeddings\n",
    "* Probabilistic FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser des modèles pré-entraînés\n",
    "\n",
    "De part l'utilisation de réseau de neurones, on considère que Word2Vec et les autres algorithmes similaires font partie du Deep Learning plutôt que du Machine Learning. Les réseaux de neurones ont permis de faire des progrès considérables dans le traitement des données. \n",
    "\n",
    "Cependant, ces progrès se sont fait au coût de modèles très lourds en terme d'espace disque et mémoire, mais aussi au coût de très nombreuses heures d'entraînement. \n",
    "\n",
    "Ainsi dans la communauté de Deep Learning, il est commun de partager son modèle une fois que celui-ci a terminé son entraînement et qu'il y a obtenu des résultats satisfaisants. Ceci est intéréssant pour différentes raisons:\n",
    "\n",
    "* Tout d'abord, cela répond à la difficulté de trouver assez de données pour entraîner un modèle similaire. Si quelqu'un a entraîné un modèle sur un problème similaire au votre, il est logique d'utiliser son modèle plutôt que d'entraîner soi-même un modèle avec moins de données, au risque donc d'obtenir de moins bons résultats.\n",
    "\n",
    "* Entraîner un bon réseau de neurones demande d'avoir une très grande quantité de données. Cependant, la puissance de calcul demandées pour traiter une telle masse de données est bien plus importante que pour les algorithmes en Machine Learning. Ainsi, peut d'ordinateur personnels sont en mesure d'entraîner de bons réseaux sans y passer des jours, voir des semaines. Utiliser un modèle pré-entraîné vous permet d'accéder à ces réseaux sans y invester à nouveau autant de temps.\n",
    "\n",
    "* Un modèle pré-entraîné peut servir de base à votre nouveau modèle. En effet, de manière simpliste, les modèles en Deep Learning peut continuer à apprendre même lorsque leur entraînement est terminé. Ainsi, des modèles peuvent avoir été entraînés sur des données très générales (ex: Wikipédia). Ces modèles sont souvents très grands et ne sont pas très efficaces. Cependant, vous pouvez les utiliser et les affiner sur vos propres données, vous permettant ainsi d'obtenir de meilleurs résultats que si vous aviez créer un modèle depuis le début. On parle alors de **transfer learning**. Nous reviendrons plus tard sur ces notions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de Word Embeddings\n",
    "\n",
    "Avant de générer par nous-mêmes des Words Embeddings, nous allons en charger un déjà entraîné afin d'en voir les différents intérêts. Gensim propose certains embeddings déjà prêts que l'on peut directement télécharger, tel que celui entraîné sur le Google News Dataset (environ 3 millions de mots). \n",
    "\n",
    "Attention, ce modèle pèse près de 2gb et peut prendre du temps à télécharger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 2.2% 36.0/1662.8MB downloaded"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-593528365eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/site-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{fname}.gz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_calculate_md5_checksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_get_checksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cours_dl/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "GloVe : https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "fastText : https://fasttext.cc/\n",
    "\n",
    "Résumés des méthodes de Word Embeddings : http://hunterheidenreich.com/blog/intro-to-word-embeddings/\n",
    "\n",
    "Post de blog sur la différence Word2Vec / fastText : https://amitness.com/2020/06/fasttext-embeddings/\n",
    "\n",
    "https://iksinc.online/tag/continuous-bag-of-words-cbow/\n",
    "\n",
    "https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/07/neural-networks-from-scratch-in-python-and-r/\n",
    "\n",
    "https://towardsdatascience.com/understanding-neural-networks-19020b758230\n",
    "\n",
    "http://jalammar.github.io/illustrated-word2vec/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "\n",
    "https://kavita-ganesan.com/comparison-between-cbow-skipgram-subword/#.X0z4CxmxVhE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqsFrkTED839+eY31PFksJ",
   "name": "Cours.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
