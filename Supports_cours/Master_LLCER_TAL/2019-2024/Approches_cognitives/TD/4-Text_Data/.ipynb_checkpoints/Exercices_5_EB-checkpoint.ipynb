{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice\n",
    "\n",
    "Pour cet exercice, vous utiliserez à nouveau la version anglaise du ``amazon_reviews``. Vous utiliserez la version binaire du dataset que vous avez produit pendant l'exercice précédent. Si vous ne l'avez pas enregistré sur le disque, refaites l'exercice précédent et sauvegardez les données.\n",
    "\n",
    "Vous allez jouer avec les différents paramètres de ``CountVectorizer`` et ``TfIdfVectorizer`` comme nous l'avons fait en cours. Contrairement au cours cependant, vous passerez par la classe ``Pipeline`` pour faire vos différents tests. \n",
    "\n",
    "Vous penserez également à valider votre modèle sur les données de validation ainsi que sur les données de test. Comme dans le cours, vous enregistrerez les performances de vos modèles afin de les visualiser dans un graphique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (par défaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 40323)\n",
      "Forme de la matrice : (4000, 40323)\n",
      "Forme de la matrice : (4000, 40323)\n",
      "0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "#dictionnaire contenant les résultats\n",
    "resultat = {}\n",
    "\n",
    "#chargement données\n",
    "train = pd.read_csv('Data_exercices/binary/bi_as_train.csv')\n",
    "dev = pd.read_csv('Data_exercices/binary/bi_as_dev.csv')\n",
    "test = pd.read_csv('Data_exercices/binary/bi_as_test.csv')\n",
    "\n",
    "#concaténation des données\n",
    "data = pd.concat([train['texts'], dev['texts'], test['texts']])\n",
    "\n",
    "#Implémentation du transformer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(data)\n",
    "\n",
    "#Transformation des données\n",
    "X_train, y_train = cv.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = cv.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = cv.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "#Entraînement \n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['cv'] = score\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (pas de mots vides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 40181)\n",
      "Forme de la matrice : (4000, 40181)\n",
      "Forme de la matrice : (4000, 40181)\n",
      "Score : 0.87075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Data_exercices/binary/bi_as_train.csv')\n",
    "dev = pd.read_csv('Data_exercices/binary/bi_as_dev.csv')\n",
    "test = pd.read_csv('Data_exercices/binary/bi_as_test.csv')\n",
    "\n",
    "fr_stopwords = []\n",
    "with open('../Cours/Data/fr_stopwords.txt') as f:\n",
    "  for line in f:\n",
    "    line = line.strip()\n",
    "    fr_stopwords.append(line)\n",
    "fr_stopwords[:10] \n",
    "# NICOLAS : la ligne ci-dessus ne sert à rien: dans Jupyter\n",
    "# si la dernière ligne d'une cellule est une variable ou une fonction, elle est directement affichée, comme si\n",
    "# tu faisais print, mais ça ne marche QUE si c'est la dernière ligne\n",
    "\n",
    "cv2 = CountVectorizer(stop_words=fr_stopwords)\n",
    "cv2.fit(data) \n",
    "\n",
    "X_train, y_train = cv2.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = cv2.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = cv2.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['cv2'] = score\n",
    "print(\"Score :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (tokenization au niveau des caractères)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 245)\n",
      "Forme de la matrice : (4000, 245)\n",
      "Forme de la matrice : (4000, 245)\n",
      "Score : 0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "analyzer = 'char' # NICOLAS: très bien\n",
    "cv3 = CountVectorizer(analyzer = analyzer)\n",
    "cv3.fit(data)\n",
    "\n",
    "X_train, y_train = cv3.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = cv3.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = cv3.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['cv3'] = score\n",
    "print(\"Score :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer (par défaut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 40323)\n",
      "Forme de la matrice : (4000, 40323)\n",
      "Forme de la matrice : (4000, 40323)\n",
      "Score : 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf1 = TfidfVectorizer()\n",
    "tf1.fit(data) \n",
    "\n",
    "X_train, y_train = tf1.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = tf1.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = tf1.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['tf1'] = score\n",
    "print(\"Score :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer (maximum 10 000 mots dans le vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 10000)\n",
      "Forme de la matrice : (4000, 10000)\n",
      "Forme de la matrice : (4000, 10000)\n",
      "Score : 0.876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf2 = TfidfVectorizer(max_features= 10000)\n",
    "tf2.fit(data) \n",
    "\n",
    "X_train, y_train = tf2.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = tf2.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = tf2.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['tf2'] = score\n",
    "print(\"Score :\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdfVectorizer (bigrammes, pas de mots vides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 969779)\n",
      "Forme de la matrice : (4000, 969779)\n",
      "Forme de la matrice : (4000, 969779)\n",
      "Score : 0.88275\n"
     ]
    }
   ],
   "source": [
    "tf3 = TfidfVectorizer(stop_words=fr_stopwords,ngram_range=(2,2)) #NICOLAS: pense à bien espacer ton code pour la lisibilité\n",
    "tf3.fit(data) \n",
    "\n",
    "X_train, y_train = tf3.transform(train['texts']), train['targets']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "X_dev, y_dev = tf3.transform(dev['texts']), dev['targets']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "X_test, y_test = tf3.transform(test['texts']), test['targets']\n",
    "print(\"Forme de la matrice :\", X_test.shape)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "score = lr.score(X_dev, y_dev)\n",
    "resultat['tf3'] = score\n",
    "print('Score :', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison visuelle des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd474094d30>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = pd.Series(resultat)\n",
    "v.plot.bar()\n",
    "# NICOLAS: du coup, à partir de ce graphique, quel est le meilleur modèle selon toi ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder le modèle le plus performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmabft/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['quelqu'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.88325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "\n",
    "#renommer les variables \n",
    "X_train, y_train = train['texts'], train['targets']\n",
    "X_dev, y_dev = dev['texts'], dev['targets']\n",
    "\n",
    "#sauvegarder le vectorizer et le modèle dans Pipeline \n",
    "pipe = Pipeline(\n",
    "[('vectorizer', TfidfVectorizer(stop_words=fr_stopwords,ngram_range=(2,2))),\n",
    "('linear', LogisticRegression())\n",
    "])\n",
    "\n",
    "#Entrainement\n",
    "pipe.fit(X_train, y_train)\n",
    "score = pipe.score(X_dev, y_dev)\n",
    "print(\"Score :\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data_exercices/pipe_model/model.joblib']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "os.mkdir('Data_exercices/pipe_model')\n",
    "dump(pipe, 'Data_exercices/pipe_model/model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
