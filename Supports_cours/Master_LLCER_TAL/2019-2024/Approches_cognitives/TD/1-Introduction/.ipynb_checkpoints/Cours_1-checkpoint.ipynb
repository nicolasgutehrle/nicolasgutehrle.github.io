{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKaet-a3r6pT"
   },
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avant le Machine Learning\n",
    "\n",
    "En TAL comme dans la plupart des domaines liés au traitement de l'information et à l'informatique, l'objectif a toujours été d'élaborer des méthodes et des systèmes capables de faire sens des données. Dans les premières décennies de l'informatique, ces systèmes fonctionnaient grâce à un ensemble de règles établies manuellement. Par opposition aux modèles automatiques fonctionnant grâce au Machine Learning, les systèmes à base de règles sont appelés ``systèmes symboliques``.\n",
    "\n",
    "\n",
    "Par exemple, on peut créer un système pour filtrer les spams des mails en utilisant par exemple un vocabulaire de termes présents dans les spams. On peut également créer des grammaires pour identifier des propositions que l'on ne retrouve que dans ce genre de mail. Ces règles auront au préalable été établies par une équipe de linguistes, qui sont experts dans l'analyse de la langue, mais aussi par une équipe de développeurs, qui implémentent ces règles pour que l'ordinateur soit capable de faire les traitements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force et faiblesse des systèmes symboliques\n",
    "\n",
    "Les systèmes symboliques, établis par des équipes d'experts du domaine traité, ont pour force de reposer sur un nombre vaste de règles très précises et qui peuvent traiter des cas très variés. Ces systèmes permettent donc d'obtenir des résultats très précis par rapport au problème traité. \n",
    "\n",
    "Cependant, développer ces règles est une tâche extrêmement fastidieuse, et qui peut prendre plusieurs mois voir plusieurs années de développement à elles seules. De plus, malgré la participation d'experts, certaines tâches restent difficiles à traiter et d'autres sont tout simplement intraitables via un système symbolique classique: les traductions automatiques étaient loin d'être parfaites; demander à un ordinateur de distinguer une pomme d'une orange était impossible jusqu'en 2001. De plus, ces systèmes étaient développés dans des domaines très précis, et s'adaptaient donc difficilement à d'autres domaines ou à des échelles plus larges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si les systèmes symboliques ne suffisaient pas à résoudre toutes les problématiques liées au traitement de l'information, il est devenu encore plus difficile de développer des systèmes efficaces pour traiter la masse de données produites liées à l'avènement du Big Data dans les années 2000. Cependant, c'est également au cours de ces années que le Machine Learning est réellement apparu, rendu possible par les progrès en informatique et à l'augmentation de la puissance de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage automatique / Approche stochastique\n",
    "\n",
    "A son apparition, le Machine Learning apportait une nouvelle approche du traitement des données. Le Machine Learning est un domaine qui regroupe plusieurs domaines des mathématiques, en particulier les statistiques, les probabilités et l'algèbre linéaire. Le fait de reposer sur un traitement avant tout mathématique fait que ces algorithmes sont biens plus adaptés au traitement du Big Data que les systèmes symboliques. Ainsi ces dernières années, le Machine Learning s'est imposé dans un nombre toujours plus grand de domaines d'études, et a permis de traiter différents problèmes tels que:\n",
    "\n",
    "* La reconnaissance d'images\n",
    "* La traduction automatique\n",
    "* La génération de texte\n",
    "* L'analyse de sentiments\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "\n",
    "On parle d'apprentissage automatique puisque contrairement au modèle symbolique, il n'y a pas besoin de définir en amont les règles permettant de résoudre une tâche: c'est l'algorithme lui-même qui va apprendre ces règles à partir des données qui lui sont données. \n",
    "\n",
    "Il existe un très grand nombre d'algorithmes, chacun traitant les données d'une manière différente et donc adaptés à différents types de problèmes. Cependant, ils sont de manière générale comparables à des fonctions mathématiques simples, comme la fonction linéaire ci-dessous:\n",
    "\n",
    "``f(y) = ax + b``\n",
    "\n",
    "Dans ces fonctions, x est la valeur donnée en entrée et y est le résultat que l'on veut obtenir, tandis que les variables a et b sont les paramètres qui vont influencer sur le résultat. Si l'on doit comparer à notre système symbolique précédent:\n",
    "\n",
    "* x est un mail issu de notre corpus\n",
    "* y est la catégorie associée à ce mail (spam ou non)\n",
    "* a et b sont les règles définies pour classer ce mail comme spam ou non\n",
    "\n",
    "Comme dit précédemment, les domaines d'application du Machine Learning sont très vastes. Cependant, on peut regrouper ces applications selon deux grandes catégories:\n",
    "\n",
    "* L'apprentissage supervisé\n",
    "* L'apprentissage non-supervisé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_nAB6Tq0tDA"
   },
   "source": [
    "# Apprentissage supervisé\n",
    "\n",
    "L'apprentissage supervisé est une des formes du Machine Learning qui englobe le plus de problèmes, et qui par conséquent est une des plus populaires et des plus pratiquées. On est dans un cas d'apprentissage supervisé lorsque nos données d'entrées x sont associées à une donnée de sortie y. \n",
    "\n",
    "Typiquement, la détection de spams est un cas d'apprentissage supervisé, puisque chaque mail de notre corpus est associé à une catégorie (spam ou non-spam). \n",
    "\n",
    "Dans cette forme de Machine Learning, l'objectif pour l'algorithme sera au cours de la phase d'entraînement de tenter de deviner pour chaque donnée la valeur à laquelle elle est associée. S'il se trompe (en prédisant qu'un mail est un spam alors qu'il ne l'est pas), l'algorithme met automatiquement à jour les paramètres (a et b par exemple) qu'il a appris, puis passe à la prochaine donnée. L'algorithme voit l'ensemble du dataset plusieurs fois jusqu'à ce que l'entraînement soit terminé. \n",
    "\n",
    "Les paramètres appris au cours de l'entraînement sont conservés, même après la phase d'apprentissage. Lorsque l'on veut associer une nouvelle donnée à une catégorie, on peut alors utiliser l'algorithme entraîné, qui se basera sur ces paramètres pour prédire un résultat. Ainsi, contrairement à un modèle symbolique, il n'y a pas besoin de repasser par toutes les règles pour obtenir le résultat, celui-ci est obtenu immédiatement.\n",
    "\n",
    "De même, l'apprentissage supervisé se divise généralement en deux types de problèmes: les problèmes de ``classification`` et les problèmes de ``régression``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jmyry25oGgrr"
   },
   "source": [
    "## Classification\n",
    "\n",
    "Dans des problèmes de classification, l'objectif est de prédire à quelle classe ou catégorie une donnée peut appartenir parmi un ensemble de catégories pré-définies.\n",
    "\n",
    "Exemples:\n",
    "\n",
    "* Déterminer si un mail est un spam ou non (classification binaire)\n",
    "* Déterminer si un tweet est positif, négatif ou neutre (classification multiclasses)\n",
    "* Déterminer à quelle variété d'iris une fleur appartient en se basant sur certaines mesures (classification multiclasses)\n",
    "* Déterminer si un tweet est positif ou négatif (classification binaire)\n",
    "\n",
    "### Note\n",
    "\n",
    "Une classification binaire peut se comparer à une question en oui / non : est-ce que ce mail est un spam ou non ? Dans ces cas-là, on parle généralement d'une classe positive (*spam*) et d'une classe (*non-spam*).\n",
    "\n",
    "## Régression\n",
    "\n",
    "Dans les problèmes de régression, l'objectif est de prédire une valeur continue à partir d'un ensemble de données. Ici la valeur prédite est un nombre réel, et ne fait donc pas partie d'un ensemble fini.\n",
    "\n",
    "Exemples:\n",
    "\n",
    "* Prédire le salaire mensuel d'une personne en fonction de son âge, son ancienneté, ses études\n",
    "* Prédire la valeur boursière d'une action par rapport aux valeurs précédentes\n",
    "* Prédire la note d'un étudiant à un contrôle par rapport à ses notes précédentes\n",
    "\n",
    "### Note\n",
    "\n",
    "A de rares exceptions, les problèmes traités par le TAL en Machine Learning sont quasi-exclusivement des problèmes de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zWe8eAQG2sO"
   },
   "source": [
    "## Apprentissage non-supervisé\n",
    "\n",
    "L'autre grande forme de Machine Learning est l'apprentissage non-supervisé (*Unsupervised Learning*). Contrairement à l'apprentissage supervisé, il n'y a pas de données de sortie associées aux données d'entrées. Ainsi, l'objectif est d'extraire automatiquement les caractéristiques des données d'entraînement.\n",
    "\n",
    "Un des avantages est que ce type d'algorithme est plus facile à appliquer à des datasets, puisque l'on a juste besoin des données d'entrées. A l'inverse, ce type de modèle est plus difficile à évaluer, puisque l'on a aucune catégories pour comparer.\n",
    "\n",
    "Ainsi, les méthodes non-supervisées sont généralement utilisées pour explorer les données (clustering, réduction du nombre de dimensions, ...) ou pour transformer les données de telle sorte à les utiliser pour un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données\n",
    "\n",
    "Pour l'apprentissage supervisé comme non-supervisé, les algorithmes de Machine-Learning ont besoin de données sous forme numérique pour pouvoir s'entraîner. En général, ces données sont représentées sous forme de matrice, ce qui nous permet d'une part d'aborder ces données plus facilement, et d'autre part permet aux algorithmes d'opérer les calculs plus rapidement. \n",
    "\n",
    "Ci-dessous, un dataset typique que l'on peut retrouver en Machine-Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "wine = load_wine()\n",
    "# boston\n",
    "data = pd.DataFrame(data = wine['data'], columns=wine['feature_names'])\n",
    "data['target'] = wine['target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce dataset contient la description de différents vins, et est composé de 178 lignes et de 13 colonnes. Chaque ligne du dataset est l'observation d'un vin différent, tandis que chaque colonne est une des caractéristique observée pour ce vin. \n",
    "\n",
    "En Machine-Learning, une observation ou une ligne d'un dataset est appelée ``sample`` tandis qu'une caractéristique ou une colonne du dataset est appelée ``feature``. Notre dataset est donc une matrice de 178 par 13, composée de 178 samples et de 13 features.\n",
    "\n",
    "### Important\n",
    "\n",
    "Une ligne ou une colonne d'une matrice est appelée un ``vecteur``. Un vecteur peut se comparer à une liste d'éléments. Le nombre d'éléments dans un vecteur est exprimé en dimension: par exemple, le vecteur ci-dessous:\n",
    "\n",
    "``[14.23 \t1.71 \t2.43 \t15.6 \t127.0 \t2.80 \t3.06]``\n",
    "\n",
    "est composé de 7 éléments. Il a donc 7 dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MX9nbo3Ntp1w"
   },
   "source": [
    "# Outils et librairies\n",
    "\n",
    "## Scikit-learn\n",
    "\n",
    "``scikit-learn`` est une des principales librairies de Machine Learning en Python. Elle permet d'utiliser un ensemble considérable d'algorithmes déjà implémentés, est extrêmement bien documentée. Bien qu'aujourd'hui elle est légèrement dépassée en terme de popularité par des librairies telles que ``Pytorch`` ou ``Tensorflow`` (qui se consacre au Deep Learning),  ``scikit-learn`` est toujours prédominent dans l'industrie comme dans la recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from scikit-learn) (1.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GH7yt2J-txXJ"
   },
   "source": [
    "## NumPy\n",
    "\n",
    "``NumPy`` est une des principales librairies de calcul en Python. Elle permet de manipuler des données très large et d'y effectuer des opérations rapidement. Aujourd'hui, toutes les librairies de traitement de données (pandas, scikit-learn, PyTorch, ...) reposent sur NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (1.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7VmDvhJt0-z"
   },
   "source": [
    "## Jupyter Notebook - Lab\n",
    "\n",
    "Jupyter (Notebook et Lab) est un environnement de travail et de développement pour Python et R très apprécié dans le milieu des data science. Il permet d'exécuter des portions de codes dans des cellules, mais aussi d'utiliser du texte, des images. C'est donc un excellent outil pour expérimenter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgsRCD-yt8PX"
   },
   "source": [
    "## Pandas\n",
    "\n",
    "``pandas`` est une librairie permettant la manipulation de données, en les représentant sous forme de ``DataFrame``, qui sont comparables à des fichiers .csv ou Excel. Reposant sur ``NumPy``, elle permet de charger rapidement des grandes quantités de données à partir de différents types de fichiers (csv, json, sqlite, ...), d'obtenir des statistiques, de les visualiser à l'aide de ``matplotlib`` et de les modifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BD_97dwUt_Ls"
   },
   "source": [
    "## matplotlib\n",
    "\n",
    "``matplotlib`` est la principale et l'une des plus anciennes librairie de visualisation de données. Elle permet de rapidement d'afficher les données sur des graphiques, les rendant plus faciles à comprendre. Très utilisé dans le milieu de la recherche, ``matplotlib`` souffre de visuels vieillisants. Pour cette raison, des librairies utilisant ``matplotlib`` comme base mais proposants des graphismes plus modernes ont vues le jour telles que ``seaborn``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (1.19.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /home/gutyh/anaconda3/envs/cours_dl/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "* Documentations:\n",
    "    * scikit-learn : https://scikit-learn.org/stable/\n",
    "    * NumPy: https://numpy.org/\n",
    "    * pandas: https://pandas.pydata.org/\n",
    "    * matplotlib: https://matplotlib.org/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6rdSlOpgSnCGSRysCLAug",
   "collapsed_sections": [],
   "name": "Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
