{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir Maison Approches Cognitives\n",
    "\n",
    "Master LLCER - parcours TAL\n",
    "Iana Atanassova, Nicolas Gutehrlé\n",
    "\n",
    "## Modalités\n",
    "\n",
    "Chaque exercice devra être réalisé dans un notebook à part. Vous rendrez un dossier contenant tous les exercices ainsi que les données et modèles que vous aurez créés. Pour simplifier l'envoi, n'hésitez pas à zipper ce dossier. Si votre fichier zip est trop lourd pour être envoyé par mail, n'hésitez pas à l'envoyer via WeTransfert.\n",
    "\n",
    "2 points sont accordés pour le détail de votre code et pour la visualisation des données. \n",
    "\n",
    "L’utilisation d’Internet ainsi que des supports de cours est autorisée. Le travail est strictement personnel. L’évaluation portera sur la compréhension des notions du cours qui sera démontrée par l’étudiant. Un entretien oral est possible suite à l’examen pour préciser la note.\n",
    "\n",
    "Ce devoir est à rendre au plus tard par mail à **nicolas.gutehrle@univ-fcomte.fr** pour le **Lundi 14 décembre**. Tout jour de retard entraînera la perte d'un point sur la note finale. Tout devoir rendu après le **21 décembre** ne sera plus accepté. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 (4pts)\n",
    "\n",
    "* Créez un nouveau dataset à partir des colonnes \"review_body\" et \"product_category\" du fichier ``multilingual_reviews.csv``.  Vous ne sélectionnerez que les données en anglais. Vous enregistrerez ce dataset dans un fichier nommé \"reviews_en.csv\", dans le dossier \"data\". Vous renommerez la colonne \"review_body\" en \"texts\" et la colonne \"product_category\" en \"classes\". Vous enregistrerez ce dataset dans un fichier nommé \"reviews_en.csv\".\n",
    "\n",
    "* Créez un nouveau dataset à partir du fichier \"HIPE-2022.tsv\", en ne sélectionnant que les colonnes \"TOKEN\" et \"NE-COARSE-LIT\". Vous renommerez les colonnes \"TOKEN\" en \"token\" et \"NE-COARSE-LIT\" en \"class\". Vous sauvegarderez ce nouveau dataset dans un fichier \"ner_dataset.csv\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 (4 pts)\n",
    "\n",
    "A partir du fichier \"reviews_en.csv\", vous entraînerez un **modèle de classification de produits**. Avant d'entraîner votre modèle, vous vous assurerez que les données soient équilibrées à l'aide d'outils de visualisation, et à employer une méthode de votre choix pour les réequilibrer si besoin. \n",
    "\n",
    "\n",
    "Vous diviserez votre dataset de telle sorte à avoir un dataset d'entraînement, de validation et de test. Vous utiliserez les datasets de validation et de test pour contrôler la qualité de votre modèle.\n",
    "\n",
    "Vous essaierez plusieurs types d'algorithmes. Une fois que vous aurez identifié l'algorithme le plus performant, vous utiliserez l'outil Pipeline de ``scikit_learn`` pour enregistrer ce modèle ainsi que le vectorizer sur le disque.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 (4 pts)\n",
    "\n",
    "A partir du fichier \"ner_dataset.csv\", entraîner un modèle CRF-linéaire pour la détection d'entités nommées. \n",
    "\n",
    "Vous diviserez votre dataset de telle sorte à avoir un dataset d'entraînement, de validation et de test. Vous utiliserez les datasets de validation et de test pour contrôler la qualité de votre modèle.\n",
    "\n",
    "Vous entraînerez plusieurs modèles, en testant différentes features. Vous sauvegarderez le meilleur modèle sur le disque à l'aide de la libraire \"joblib\". \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 (3 pts)\n",
    "\n",
    "A partir du fichier \"reviews_en.csv\", vous entraînerez un modèle de langue n-gramme à l'aide de la librairie ``NLTK``. Vous n'utiliserez que la colonne \"texts\" du dataset. Une fois le modèle entraîné, vous vous en servirez pour générer deux textes différents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 (3 pts)\n",
    "\n",
    "A partir du fichier \"reviews_en.csv\", vous entraînerez un modèle Word2Vec à l'aide de la librairie ``gensim``. Vous n'utiliserez que la colonne \"texts\" du dataset. Une fois le modèle entraîné, vous l'utiliserez pour montrer sa qualité en réalisant les tâches ci-dessous. Vous pourrez choisir les mots que vous souhaitez pour réaliser ces tâches.\n",
    "\n",
    "* Calculer la similarité entre deux mots\n",
    "* Identifer les mots les plus similaires à un mot donné\n",
    "* Calculer la similarité entre deux vecteurs\n",
    "\n",
    "Vous enregistrerez ensuite votre modèle sur le disque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
