{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vers un système de détection automatique de la langue\n",
    "\n",
    "Nous allons construire un systeme simple permettant de detecter automatiquement la langue d'un texte.\n",
    "\n",
    "Pour cela vous allez vous baser sur la méthode des N-grammes, qui a déjà fait ces preuves pour la détection de la langue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tout d'abord choisir les langues avec lesquelles nous allons travailler.\n",
    "\n",
    "1. Choisissez trois langues parmi les langues suivantes :\n",
    "*anglais, dannois, espagnol, esperanto, français, italien, latin, portugais, roumain, suedois*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Téléchargez quelques livres de chaque langue choisie en format \"Texte brut UTF-8\" à partir du site https://www.gutenberg.org/catalog/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des unigrammes\n",
    "\n",
    "Nous allons écrire un programme qui calcule les fréquences des mots dans les livres. Pour chaque langue, le programme produira un fichier texte qui contient les mots rencontrés dans les livres de cette langue. Ces mots seront ordonnées par ordre de leur fréquence, du plus fréquent au moins fréquent, et chaque mot se trouvera sur une nouvelle ligne.\n",
    "\n",
    "Comme résultat final, nous aurons des fichiers texte (par ex. fr-freq-1n.txt, en-freq-1n.txt, es-freq-1n.txt), chaque fichier contenant une liste de mots en commencant par les mots les plus fréquents dans les livres analysés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapes :\n",
    "\n",
    "Pour chaque langue :\n",
    "1. extraire les textes à partir des fichiers \n",
    "- enlever les signes de ponctuation\n",
    "- découper en mots (par ex. avec texte.split())\n",
    "- créer un dictionnaire contenant les mots (unigrammes) comme clés et leurs fréquences comme valeurs\n",
    "- ordonner la liste des mots par rapport aux fréquences\n",
    "- enregistrer le résultat dans un fichier texte\n",
    "\n",
    "Chaque étape pourra être faite dans une fonction séparée pour mieux organiser le code et pouvoir les réutiliser par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extraire_texte(fichiers):\n",
    "    \"\"\"Fonction qui extrait les textes a partir d'une liste de fichiers\"\"\"\n",
    "    texte = \"\"\n",
    "    for nom_fichier in fichiers:\n",
    "        f = open(nom_fichier, \"r\", encoding=\"utf-8\")\n",
    "        texte += f.read()\n",
    "        f.close()\n",
    "    return texte\n",
    "\n",
    "def ponctuation(texte):\n",
    "    \"\"\"Fonction qui enleve la ponctuation du texte et le convertit\n",
    "    en minuscules.\"\"\"\n",
    "    texte = re.sub(r\"[\\.\\-!\\?,;:'\\\"]\", \"\", texte)\n",
    "    texte = texte.lower()\n",
    "    return texte\n",
    "\n",
    "def decouper_en_mots(texte):\n",
    "    \"\"\"Fonction qui decoupe en mots\"\"\"\n",
    "    return texte.split()\n",
    "\n",
    "def unigrammes(liste_mots):\n",
    "    \"\"\"Fonction qui produit un dictionnaire d'unigrammes\"\"\"\n",
    "    d = {}\n",
    "    for mot in liste_mots :\n",
    "        if mot in d:\n",
    "            d[mot] += 1\n",
    "        else :\n",
    "            d[mot] = 1\n",
    "    return d\n",
    "\n",
    "def trier_dictionnaire(d):\n",
    "    \"\"\"Fonction qui trie un dictionnaire par rapport aux valeurs\"\"\"\n",
    "    d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return d\n",
    "\n",
    "def enregistrer(d, nom_fichier, limit):\n",
    "    \"\"\"Fonction qui enregistre le debut d'un dictionnaire dans un fichier texte\"\"\"\n",
    "    f = open(nom_fichier, \"w\")\n",
    "    counter = 0\n",
    "    for k in d:\n",
    "        counter += 1\n",
    "        f.write(k + \"\\n\")\n",
    "        if (counter > limit) :\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "texte_fr = extraire_texte( [\"livres/fr-5423-0.txt\", \"livres/fr-pg19657.txt\"] )\n",
    "texte_es = extraire_texte( [\"livres/es-2000-0.txt\", \"livres/es-57982-0.txt\"] )\n",
    "texte_sw = extraire_texte( [\"livres/sw-56967-0.txt\", \"livres/sw-pg14073.txt\"] )\n",
    "\n",
    "textes = [ texte_fr, texte_es, texte_sw ]\n",
    "langues = [\"fr\", \"es\", \"sw\"]\n",
    "\n",
    "# traitement des unigrammes\n",
    "for i in range(3):\n",
    "    t = textes[i]\n",
    "    langue = langues[i]\n",
    "    t = ponctuation(t)\n",
    "    liste_mots = decouper_en_mots(t)\n",
    "    \n",
    "    dict_unigr = unigrammes(liste_mots)\n",
    "    dict_unigr = trier_dictionnaire(dict_unigr)\n",
    "    \n",
    "    enregistrer(dict_unigr, \"livres/\"+langue+\"-1grams.txt\", 500)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des bi-grammes\n",
    "\n",
    "Cette fois-ci nous nous intéressons à des suites de deux mots dans les livres. Le programme produira un fichier texte, pour chaque langue, qui contient les suites de deux mots (ou bigrammes) rencontrées dans les livres de cette langue. Ces bigrammes seront ordonnées par ordre de leur fréquence, de la plus fréquente à la moins fréquente, et chaque bigramme se trouvera sur une nouvelle ligne.\n",
    "\n",
    "Comme résultat final, nous aurons des fichiers texte (par ex. fr-freq-2n.txt, en-freq-2n.txt, es-freq-2n.txt), chaque fichier contenant une liste de bigrammes en commencant par celles les plus fréquentes dans les livres analysés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrammes(liste_mots):\n",
    "    \"\"\"Fonction qui retourne la liste des bi-grammes et leurs frequences.\"\"\"\n",
    "    d = {}\n",
    "    for i in range(len(liste_mots)-1):\n",
    "        # construction de la bi-gramme\n",
    "        bigramme = liste_mots[i] + \" \" + liste_mots[i+1]\n",
    "        # ajout dans le dictionnaire\n",
    "        if bigramme in d:\n",
    "            d[bigramme] += 1\n",
    "        else :\n",
    "            d[bigramme] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapes :\n",
    "\n",
    "A partir de la liste des mots (étape 3 plus haut) :\n",
    "7. créer la liste des bi-grammes\n",
    "- créer un dictionnaire contenant les bi-grammes comme clés et leurs fréquences comme valeurs\n",
    "- ordonner la liste par rapport aux fréquences\n",
    "- enregistrer le résultat dans un fichier texte\n",
    "\n",
    "Chaque étape pourra être faite dans une fonction séparée pour mieux organiser le code et pouvoir les réutiliser par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement des bigrammes\n",
    "for i in range(3):\n",
    "    t = textes[i]\n",
    "    langue = langues[i]\n",
    "    t = ponctuation(t)\n",
    "    liste_mots = decouper_en_mots(t)\n",
    "    \n",
    "    dict_bigr = bigrammes(liste_mots)\n",
    "    dict_bigr = trier_dictionnaire(dict_bigr)\n",
    "    \n",
    "    enregistrer(dict_bigr, \"livres/\"+langue+\"-2grams.txt\", 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la similarité entre listes de fréquences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrivez une fonction qui permet de calculer la similarité entre 2 listes ordonnées. Les listes pourront contenir des mots ou des bigrammes. On attribue un poids à chaque élement des 2 listes : ce poids est égal au nombre d'élements de la liste la plus courte et diminue d'un pour chaque position (voir les exemples ci-dessous). La fonction calculera la valeur S pour les deux listes L1 et L2 en prennant la somme des produits des poids des éléments communs. \n",
    "\n",
    "Voici un exemple :\n",
    "\n",
    "L1 = [a, b, c, d, e]\t\tavec poids [5, 4, 3, 2, 1]\n",
    "\n",
    "L2 = [a, b, f, c, g, d]\t\tavec poids [5, 4, 3, 2, 1, 0]\n",
    "\n",
    "\n",
    "S(L1, L2) = 5 * 5 +4 * 4 + 2 * 3 + 0 * 2 = 25 + 16 + 6 + 0 = 47\n",
    "\n",
    "(Pour chaque élément commun, on ajoute le produit de son poids dans L2 et dans L1)\n",
    "\n",
    "Autre exemple :\n",
    "\n",
    "L1 = [a, b, c, d, e]\t\t\tavec poids [5, 4, 3, 2, 1]\n",
    "\n",
    "L3 = [b, f, g, h, d, a, b, c]\t\tavec poids [5, 4, 3, 2, 1, 0, 0, 0]\n",
    "\n",
    "S(L1, L3) = 4 * 5 + 1 * 2 + 0 * 5 + 0 * 4 + 0 * 3 = 20 + 2 + 0 + 0 + 0 = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simListe(l1, l2):\n",
    "    sim = 0\n",
    "    \n",
    "    # on considère la longeur de la liste la plus courte\n",
    "    l = len(l1)\n",
    "    if (l>len(l2)) :\n",
    "        l = len(l2)\n",
    "    \n",
    "    # une boucle pour tous les elements de la liste la plus courte\n",
    "    for i in range(l):\n",
    "        # element de l1\n",
    "        el = l1[i]\n",
    "        # poids de cet element :\n",
    "        p1 = l-i\n",
    "        \n",
    "        if (el in l2):\n",
    "            # position de l'element dans l2\n",
    "            pos = l2.index(el)\n",
    "            # poids de cet element dans l2\n",
    "            p2 = l - pos\n",
    "            \n",
    "            if (p2>0) :\n",
    "                sim += p1*p2\n",
    "    \n",
    "    return sim       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# test de la fonction simListe()\n",
    "L1 = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "L2 = [\"a\", \"b\", \"f\", \"c\", \"g\", \"d\"]\n",
    "L3 = [\"b\", \"f\", \"g\", \"h\", \"d\", \"a\", \"b\", \"c\"]\n",
    "\n",
    "print (simListe(L1, L2))\n",
    "print (simListe(L1, L3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programme final\n",
    "\n",
    "Ecrivez le programme final qui permet d'analyser un nouveau texte (dans une langue inconnue) qui se trouve dans un fichier entree.txt. Pour tester le programme, ce texte peut être assez court (une phrase ou un paragraphe). \n",
    "\n",
    "Comparez le résultat de votre programme avec le démontrateur qui se trouve ici :  https://detectlanguage.com/ (demo en bas a droite de la page).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarités des unigrammes :\n",
      "fr : 59921\n",
      "es : 65684\n",
      "sw : 33722\n",
      "Langue la plus probable :\n",
      "es\n",
      "Similarités des bigrammes :\n",
      "fr : 0\n",
      "es : 0\n",
      "sw : 0\n",
      "Langue la plus probable :\n",
      "fr\n"
     ]
    }
   ],
   "source": [
    "# lecture du fichier entree.txt et traitement \n",
    "texte_entree = extraire_texte( [\"entree.txt\"] )\n",
    "texte_entree = ponctuation(texte_entree)\n",
    "liste_mots = decouper_en_mots(texte_entree)\n",
    "\n",
    "# unigrammes du texte entree.txt\n",
    "dict_unigr = unigrammes(liste_mots)\n",
    "dict_unigr = trier_dictionnaire(dict_unigr)\n",
    "\n",
    "liste_unigr = list(dict_unigr.keys())\n",
    "\n",
    "# bigrammes du texte entree.txt\n",
    "dict_bigr = bigrammes(liste_mots)\n",
    "dict_bigr = trier_dictionnaire(dict_bigr)\n",
    "\n",
    "liste_bigr = list(dict_bigr.keys())\n",
    "\n",
    "# comparaison de la liste obtenue avec les differentes listes par langue :\n",
    "sim_unigr = []\n",
    "sim_bigr = []\n",
    "\n",
    "for i in range(3):\n",
    "    langue = langues[i]\n",
    "\n",
    "    # extraction des unigrammes et bigrammes pour cette langue à partir des fichiers\n",
    "    langue_unigr = []\n",
    "    f = open(\"livres/\"+langue+\"-1grams.txt\")\n",
    "    for ligne in f :\n",
    "        langue_unigr.append(ligne.strip())\n",
    "    f.close()\n",
    "    \n",
    "    langue_bigr = []\n",
    "    f = open(\"livres/\"+langue+\"-2grams.txt\")\n",
    "    for ligne in f :\n",
    "        langue_bigr.append(ligne.strip())\n",
    "    f.close()\n",
    "    \n",
    "    # calcul des similarites :\n",
    "    sim1 = simListe(liste_unigr, langue_unigr)\n",
    "    sim2 = simListe(liste_bigr, langue_bigr)\n",
    "    \n",
    "    sim_unigr.append(sim1)\n",
    "    sim_bigr.append(sim2)\n",
    "\n",
    "# Affichage du resultat : la langue la plus probable est celle où la similarité est la plus grande\n",
    "print(\"Similarités des unigrammes :\")\n",
    "for i in range(3):\n",
    "    print(langues[i] + \" : \" + str(sim_unigr[i]))\n",
    "print(\"Langue la plus probable :\")\n",
    "max_val = max(sim_unigr)\n",
    "pos = sim_unigr.index(max_val)\n",
    "langue = langues[pos]\n",
    "print(langue)\n",
    "\n",
    "print(\"Similarités des bigrammes :\")\n",
    "for i in range(3):\n",
    "    print(langues[i] + \" : \" + str(sim_bigr[i]))\n",
    "print(\"Langue la plus probable :\")\n",
    "max_val = max(sim_bigr)\n",
    "pos = sim_bigr.index(max_val)\n",
    "langue = langues[pos]\n",
    "print(langue)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
