{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir Maison Approches Cognitives\n",
    "\n",
    "Master LLCER - parcours TAL\n",
    "Iana Atanassova, Nicolas Gutehrlé\n",
    "\n",
    "## Modalités\n",
    "\n",
    "Chaque exercice devra être réalisé dans un notebook à part. Vous rendrez un dossier contenant tous les exercices ainsi que les données et modèles que vous aurez créés. Pour simplifier l'envoi, n'hésitez pas à zipper ce dossier. Si votre fichier zip est trop lourd pour être envoyé par mail, n'hésitez pas à l'envoyer via WeTransfert.\n",
    "\n",
    "2 points sont accordés pour le détail de votre code et pour la visualisation des données. Pensez donc bien à commenter le plus possible ! \n",
    "\n",
    "L’utilisation d’Internet ainsi que des supports de cours est autorisée. Le travail est strictement personnel. L’évaluation portera sur la compréhension des notions du cours qui sera démontrée par l’étudiant. Un entretien oral est possible suite à l’examen pour préciser la note.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 (4pts)\n",
    "\n",
    "Créez un nouveau dataset à partir des colonnes \"review_body\" et \"product_category\" du fichier ``multilingual_reviews.csv``.  Vous ne sélectionnerez que les données en anglais. Vous enregistrerez ce dataset dans un fichier nommé \"reviews_en.csv\", dans le dossier \"data\". Vous renommerez la colonne \"review_body\" en \"texts\" et la colonne \"product_category\" en \"classes\". Vous enregistrerez ce dataset dans un fichier nommé \"reviews_en.csv\".\n",
    "\n",
    "Créez un nouveau dataset à partir des colonnes \"review_body\" et \"language\" du fichier ``multilingual_reviews.csv``. Vous enregistrerez ce dataset dans un fichier nommé \"reviews_en.csv\", dans le dossier \"data\". Vous renommerez la colonne \"review_body\" en \"texts\" et la colonne \"product_category\" en \"lg\". Vous enregistrerez ce dataset dans un fichier nommé \"multilingual_dataset.csv\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 (4 pts)\n",
    "\n",
    "A partir du fichier \"multilingual_dataset.csv\", vous entraînerez un **modèle de reconnaissance de langue**. \n",
    "\n",
    "Vous vous servirez d'outils de visualisation pour observer les données et noter tous commentaires que vous pouvez avoir. \n",
    "\n",
    "Vous diviserez votre dataset de telle sorte à avoir un dataset d'entraînement, de validation et de test. Vous utiliserez les datasets de validation et de test pour contrôler la qualité de votre modèle.\n",
    "\n",
    "Vous encoderez les données à l'aide de CountVectorizer et / ou TfIdfVectorizer. Vous utiliserez au moins deux CountVectorizer et deux TfIdfVectorizer, chacun avec des paramètres différents (ex: supprimer les mots vides, tokenizer aux caractères...) \n",
    "\n",
    "Pour chaque version des données encodées, vous entraînerez un modèle LogisticRegression et un modèle KNN. \n",
    "\n",
    "Vous enregistrerez les résultats de chaque modèle pour chaque type d'encodage, de telle sorte à pouvoir comparer les résultats à la fin à l'aide de graphique. Vous commenterez les résultats obtenus.  \n",
    "\n",
    "Une fois que vous aurez identifié l'algorithme le plus performant, vous utiliserez l'outil Pipeline de ``scikit_learn`` pour enregistrer ce modèle ainsi que le vectorizer correspondant sur le disque.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 (4 pts)\n",
    "\n",
    "A partir du fichier \"reviews_en.csv\", vous entraînerez un modèle Word2Vec à l'aide de la librairie ``gensim``. Vous n'utiliserez que la colonne \"texts\" du dataset. \n",
    "\n",
    "Une fois le modèle entraîné, vous l'utiliserez pour montrer sa qualité en réalisant les tâches ci-dessous. Vous pourrez choisir les mots que vous souhaitez pour réaliser ces tâches.\n",
    "\n",
    "* Calculer la similarité entre deux mots\n",
    "* Identifer les mots les plus similaires à un mot donné\n",
    "* Calculer la similarité entre deux vecteurs\n",
    "* Représenter les 50 premiers mots des Word Embeddings sous forme de graphique\n",
    "\n",
    "Vous enregistrerez ensuite votre modèle sur le disque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 (4 pts)\n",
    "\n",
    "A partir du fichier \"multilingual_dataset.csv\", vous entraînerez un **modèle de classification de produits**. \n",
    "\n",
    "Vous vous servirez d'outils de visualisation pour observer les données et noter tous commentaires que vous pouvez avoir. \n",
    "\n",
    "Vous diviserez votre dataset de telle sorte à avoir un dataset d'entraînement, de validation et de test. Vous utiliserez les datasets de validation et de test pour contrôler la qualité de votre modèle.\n",
    "\n",
    "Vous encoderez les données à l'aide de du modèle de Word embeddings que vous avez entraîné dans l'exercice précédent.   \n",
    "\n",
    "Vous entraînerez un modèle LogisticRegression et un modèle KNN. \n",
    "\n",
    "Vous enregistrerez les résultats de chaque modèle, de telle sorte à pouvoir comparer les résultats à la fin à l'aide de graphique. Vous commenterez les résultats obtenus.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 (4 pts)\n",
    "\n",
    "A l'aide d'Ollama via Python et du modèle Phi-3.5, réalisez les tâches de **classification de produits** et de **catégorisation de langue**. \n",
    "\n",
    "Pour chaque tâche, vous demanderez au modèle de catégoriser une phrase (soit en produit, soit en langue). La phrase proviendra des données précédentes. \n",
    "\n",
    "Pour chaque tâche, vous utiliserez  deux prompts différents : \n",
    "* un qui comporte des exemples de phrases annotées\n",
    "* un autre qui n'en comporte pas\n",
    "\n",
    "Les prompts utilisés doivent être rendus avec ce DM (le code que vous avez rédigé avec Ollama peut suffire pour cela).\n",
    "\n",
    "Vous pouvez travailler votre prompt et sa mise en page comme vous le souhaitez. \n",
    "\n",
    "Vous sauvegarderez chaque réponse générée par le modèle sur le disque au format .txt. Vous commenterez chaque réponse produite. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
