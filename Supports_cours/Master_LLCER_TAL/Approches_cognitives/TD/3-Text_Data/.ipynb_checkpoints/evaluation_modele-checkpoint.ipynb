{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1bUY3xdp9wf"
   },
   "source": [
    "# Evaluer son modèle\n",
    "\n",
    "On peut entraîner son modèle le temps que l'on veut et avec autant de données que l'on veut, à la fin il faudra voir si l'entraînement s'est bien passé et si le modèle a réellement appris quelque chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6n-FWx6uI0o"
   },
   "source": [
    "### Chargement d'un modele et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1594384880787,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "YIXDCwLauQBv",
    "outputId": "2ed0a09b-743c-473b-b495-7af1acbc9d22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ca c'est du vol... Vous ne recevrez q'une lame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presque 1 mois après la commande, le produit n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon n’a pu me livrer ce produit, je suis dé...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pas adapté au boîtier, il flotte dedans.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heureusement qu'Amazon a le sens des affaires,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  labels\n",
       "0  Ca c'est du vol... Vous ne recevrez q'une lame...       0\n",
       "1  Presque 1 mois après la commande, le produit n...       0\n",
       "2  Amazon n’a pu me livrer ce produit, je suis dé...       0\n",
       "3           Pas adapté au boîtier, il flotte dedans.       0\n",
       "4  Heureusement qu'Amazon a le sens des affaires,...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "testpath = '/content/drive/My Drive/Cours/Classification_binaire/data/binary_dataset_fr_test.json' \n",
    "data = pd.read_csv(testpath)\n",
    "data = data[['review_body', 'stars']]\n",
    "data.columns = ['texts', 'labels']\n",
    "X_test, y_test = data.texts, data.labels\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0amx7-Eu-4S"
   },
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "model = load('/content/drive/My Drive/Cours/Classification_binaire/linear_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v75eS7nSq-gu"
   },
   "source": [
    "## Score de précision\n",
    "\n",
    "Dans des problèmes de classification, le premier score qui nous intéresse est la précision, c'est-à-dire la capacité d'un modèle à correctement catégoriser une donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 757,
     "status": "ok",
     "timestamp": 1594388484502,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "cHMKNPrLvhXW",
    "outputId": "6eb43698-dbd2-4f9a-96de-bc02e3efe724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle :  0.88575\n",
      "Précision du modèle :  0.88575\n"
     ]
    }
   ],
   "source": [
    "# La plupart des modèles de scikit-learn ont une fonction score pour évaluer la performance\n",
    " # en entrée on donne un nouveau jeu de données avec un ensemble de catégorie pour comparer\n",
    "# les classes prédites avec les classes réelles\n",
    "print(\"Précision du modèle : \", model.score(X_test, y_test))\n",
    "\n",
    "# on peut également utiliser la fonction accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "preds = model.predict(X_test)\n",
    "print(\"Précision du modèle : \", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvAX1mVSqQYY"
   },
   "source": [
    "## Matrice de confusion - Confusion matrix\n",
    "\n",
    "Un des inconvénient du score de précision est qu'il ne donne qu'un aperçu général de la capacité du modèle à catégoriser des données. Même si un modèle est précis à 80% ou 90%, il reste toujours un pourcentage d'erreur à corriger, que le score de précision ne permet pas de consulter.\n",
    "\n",
    "Pour mieux comprendre quelles catégories sont correctement et incorrectement annotées, on peut utiliser une **matrice de confusion**\n",
    "\n",
    "[Définition sur Wikipédia ](https://fr.wikipedia.org/wiki/Matrice_de_confusion)\n",
    "\n",
    "Documentations:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix\n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1594388473455,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "Dsuvf1Nk0Z-G",
    "outputId": "5a9d5a44-81c8-4cc5-bee1-37d3af2ebf84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1759,  241],\n",
       "       [ 216, 1784]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion matrix :\")\n",
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1594386254356,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "NOi21v7R0dWG",
    "outputId": "8f1b6a8e-7fa1-4059-a174-5018d6853703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fd896a77c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Autre façon de faire, plus graphique\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "class_names = [0, 1] # on indique les classes pour mieux comprendre la matrice\n",
    "cmap = plt.cm.Blues # change les couleurs par défaut de la matrice\n",
    "\n",
    "# plot_confusion_matrix prend le modele et les données de tests et fait une\n",
    "# prediction sur ces données, pour ensuite afficher le résultat \n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                      display_labels = class_names,\n",
    "                      cmap = cmap,\n",
    "                      normalize = 'true' # permet de situer les résultats dans une échelle entre 0 et 1\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCrJB8d353qo"
   },
   "source": [
    "## Rappel (Recall)\n",
    "\n",
    "Parmis les mesures proposées par scikit-learn, on peut également calculer le Rappel. Cependant, c'est une mesure que l'on utilise rarement voir jamais dans les problèmes de classifications.\n",
    "\n",
    "Documentation: \n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1594388295298,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "H7Fr3y0v6u4V",
    "outputId": "b4d4dcbb-4d19-4705-fbb9-31ea5909a63f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.892"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CU05alNl1mFK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yyDe0EIn2F5f"
   },
   "source": [
    "## Rapport de classification\n",
    "\n",
    "Le rapport de classification regroupe un ensemble de statistiques, en particulier la Précision, le Rappel et le score F1. La fonction est donc très utile pour avoir un aperçu global des résultats du modèle.\n",
    "\n",
    "Documentations:\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1594388401385,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "gahBhloq2KXf",
    "outputId": "5522233b-e211-463f-ce30-2a7ab92bc6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      2000\n",
      "           1       0.88      0.89      0.89      2000\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.89      0.89      0.89      4000\n",
      "weighted avg       0.89      0.89      0.89      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0', '1'] # liste des noms de classes \n",
    "print(classification_report(y_test, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFEuURAZrssf"
   },
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPAQRiBoyS2p"
   },
   "source": [
    "## Jeux de données - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huY9b69tv8Cs"
   },
   "source": [
    "### Train\n",
    "\n",
    "\n",
    "Pour créer un modèle, on a besoin de données d'entraînement. En général, lorsque l'on obtient ces données d'un site (Kaggle, Google, Amazon, ...), ces données sont nommées \"train_set\", \"train_dataset\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3AxYYNLv8F0"
   },
   "source": [
    "## Validation\n",
    "\n",
    "Cependant, il est également important de pouvoir évaluer la qualité de l'entraînement. Pour cela on utilise un jeu de données dit de \"validation\" ou de \"developpement\", généralement appelé **valset** ou **devset**. Parfois, les données de validation sont fournis avec les données d'entraînement, mais ce n'est pas toujours le cas. Ainsi en général, on créé les données de validation en prenant une portion des données d'entraînement. Tradiotionnellement, on conserve 70 - 80 ou 90% des données d'entraînement et on prend le reste pour les données de validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLZG6CNprvcO"
   },
   "source": [
    "## Test set\n",
    "\n",
    "Les données d'entraînement et de validation peuvent servir à entraîner plusieurs modèles. Afin de réellement voir lequel est le plus performant, on utilise également des données de **test**, généralement appelé **testset**. Il s'agit de données que le modèle n'aura jamais vu pendant la phase d'entraînement, ce qui permet de tester les performances du modèles dans une situation réelles. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNrgUzz6wRxC"
   },
   "source": [
    "## Entraîner un modèle \n",
    "\n",
    "Dans un tâche d'apprentissage supervisé, l'objectif pour un modèle est de définir les meilleurs paramètres pour une certaine fonction à partir des données qui lui sont présentées. L'objectif à terme d'un modèle est d'être utilisé en production pour prédire des résultats à partir de nouvelles données qu'il n'a jamais vues. Ainsi, lors de l'entraînement d'un modèle, il est important d'évaluer sa capacité à **généraliser**. \n",
    "\n",
    "Cependant, il est très fréquent de créer des lodèles qui ne soient pas correctement capables de généraliser. Cette difficulté à généraliser peut s'expliquer de deux manières : soit le modèle n'est pas capable d'apprendre les paramètres à partir des données, soit au contraitre il apprend ces paramètres beaucoup trop bien. Dans le premier cas, le modèle est \"mal-entraîné\" et prédit un résultat au hasard. Dans le second, le modèle a tellement bien appris à partir des données d'entraînement qu'il ne sait pas comment traiter de nouvelles données. \n",
    "\n",
    "En machine-learning, on parle respectivement d'**underfitting** et d'**overfitting**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ke2RRF56rP2U"
   },
   "source": [
    "## Underfitting\n",
    "\n",
    "L'underfitting désigne le cas où le modèle n'a pas appris correctement les paramètres à partir des données d'entraînement, et n'est donc pas capable de généraliser. On peut le repérer lorsque les résultats de l'entraînement ne sont pas concluants. \n",
    "\n",
    "En général, l'underfitting est dû à des données n'ayant pas assez de **features**. Ainsi, la meilleure façon de résoudre l'underfitting est d'ajouter des **features** aux données.\n",
    "\n",
    "Les cas d'underfitting sont extrêmement rares lorsque l'on manipule des données textuelles, puisque justement, on a généralement beaucoup trop de features.\n",
    "\n",
    "![alt text](\"4-Classification_binaire/data/appfitting.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruNksZRYrOBS"
   },
   "source": [
    "## Overfitting\n",
    "\n",
    "L'**overfitting** désigne le cas inverse où un modèle apprend beaucoup trop bien les paramètres à partir des données d'entraînement, et n'apprend donc pas à généraliser. D'une certaine façon, le modèle a appris par coeur les réponses aux questions, mais ne sait pas quoi répondre à des questions qu'il n'a pas vu jusque là.\n",
    "\n",
    "En général, l'overfitting se détecte lorsque les performances du modèles sont largement supérieures sur les données d'entraînement que sur les données de test.\n",
    "Contrairement à l'underfitting, l'overfitting est un des problèmes les plus souvent rencontrés en machine-learning.\n",
    "\n",
    "Attention cependant à ne pas mettre un modèle de côté à cause d'un léger cas d'overfitting. Très souvent, les modèles ont tendance à l'overfit, sans que cela ne soit réellement impactant. Ainsi, on peut dire qu'un modèle généralise correctement si l'écart entre la précision de l'entraînement et du test est inférieur à 10%.\n",
    "\n",
    "EXEMPLES\n",
    "\n",
    "EXEMPLE OVERFITTING\n",
    "\n",
    "![alt text](4-Classification_binaire/data/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOf_IgX1zCcy"
   },
   "source": [
    "### Feature reduction\n",
    "\n",
    "Une des raisons de l'overfitting est qu'il y a trop de features dans les données d'entraînement, ce qui fait que les paramètres appris sont beaucoup trop précis. Une solution est donc de réduire le nombre de features.\n",
    "\n",
    "Lorsque l'on traite des données textuelles, les features utilisées correspondent au vocabulaire utilisé. En plus de préserver la mémoire, il est donc conseillé de réduire la taille de ce vocabulaire, afin que le modèle ne se concentre que sur un ensemble de mots pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6rGgFt98hSL"
   },
   "source": [
    "## Curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5J7Q1Xe1ynUT"
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-TFTjvdxetn"
   },
   "source": [
    "## Le dilemme biais-variance - The bias-variance tradeoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VrDOVumrrzR"
   },
   "source": [
    "# Références\n",
    "\n",
    "MachineLearningMastery : https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\n",
    "\n",
    "Data Science from scratch\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvuGXZt+fuDM64ZyrafsHN",
   "collapsed_sections": [],
   "mount_file_id": "1Fbj8f2yIvAVHE1KnktrjNbDGUvzCJkQG",
   "name": "evaluation_modele.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
