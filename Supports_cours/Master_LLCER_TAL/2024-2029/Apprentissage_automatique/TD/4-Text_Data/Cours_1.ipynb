{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donnée textuelles - Partie 1\n",
    "\n",
    "Comme nous l'avons vu précédemment, les algorithmes utilisés en ML demandent que les entrées soient sous formes numériques, qu'il s'agisse des données elles-mêmes ou des classes. Pour cette raison, nous avons dans le cours précédent encodés numériquement les classes de variété d'iris, tout en créant un mapping permettant de faire correspondre le nom de chaque variété à sa forme numérique.\n",
    "\n",
    "Cependant, s'il est relativement aisé d'encoder un ensemble de noms de classes, qui sont alors en nombre fini, quand est-il de données textuelles brutes, tel que des avis, des romans ou des articles ? Comment peut-on représenter la sémantique ou la syntaxe d'un texte de manière numérique ? Une grande partie des recherches en TAL (ou NLP) du point de vue du Machine Learning consiste à trouver de nouvelles méthodes pour répondre à cette problématique.\n",
    "\n",
    "Dans ce cours, nous allons voir les premières méthodes utilisés pour encoder des données textuelles, ce qui nous permettra de traiter un problème d'analyse de sentiment, qui est un cas récurrent de classification en TAL.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler à partir de la version française du ``amazon_reviews`` dataset. Contrairement aux datasets que nous avons utilisés précédemment, celui-ci est déjà divisé en train, validation et test sets. Ceux-ci sont enregistrés au format JSON, mais nous pouvons tout de même les ouvrir avec ``pandas``:\n",
    "\n",
    "### Importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trainset = pd.read_json('data/amazon_reviews/fr/train/dataset_fr_train.json', lines=True)\n",
    "devset = pd.read_json('data/amazon_reviews/fr/dev/dataset_fr_dev.json', lines=True)\n",
    "testset = pd.read_json('data/amazon_reviews/fr/test/dataset_fr_test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr_0424335</td>\n",
       "      <td>product_fr_0297678</td>\n",
       "      <td>reviewer_fr_0961886</td>\n",
       "      <td>1</td>\n",
       "      <td>A déconseiller - Article n'a fonctionné qu'une...</td>\n",
       "      <td>Brumisateur à pompe</td>\n",
       "      <td>fr</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr_0452615</td>\n",
       "      <td>product_fr_0613288</td>\n",
       "      <td>reviewer_fr_0857499</td>\n",
       "      <td>1</td>\n",
       "      <td>Si vous voulez être déçu achetez le produit ! ...</td>\n",
       "      <td>Insatisfaisant</td>\n",
       "      <td>fr</td>\n",
       "      <td>baby_product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr_0407673</td>\n",
       "      <td>product_fr_0571250</td>\n",
       "      <td>reviewer_fr_0383240</td>\n",
       "      <td>1</td>\n",
       "      <td>Écran de mauvaise qualité, car il s'use en peu...</td>\n",
       "      <td>Ne recommande pas</td>\n",
       "      <td>fr</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr_0579191</td>\n",
       "      <td>product_fr_0030168</td>\n",
       "      <td>reviewer_fr_0729693</td>\n",
       "      <td>1</td>\n",
       "      <td>Cet engin ne sert à rien les sons sont pourris...</td>\n",
       "      <td>A éviter!</td>\n",
       "      <td>fr</td>\n",
       "      <td>musical_instruments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_0931533</td>\n",
       "      <td>product_fr_0468261</td>\n",
       "      <td>reviewer_fr_0734066</td>\n",
       "      <td>1</td>\n",
       "      <td>Très beau produit mais la grue n'a pas fonctio...</td>\n",
       "      <td>Déçue</td>\n",
       "      <td>fr</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  fr_0424335  product_fr_0297678  reviewer_fr_0961886      1   \n",
       "1  fr_0452615  product_fr_0613288  reviewer_fr_0857499      1   \n",
       "2  fr_0407673  product_fr_0571250  reviewer_fr_0383240      1   \n",
       "3  fr_0579191  product_fr_0030168  reviewer_fr_0729693      1   \n",
       "4  fr_0931533  product_fr_0468261  reviewer_fr_0734066      1   \n",
       "\n",
       "                                         review_body         review_title  \\\n",
       "0  A déconseiller - Article n'a fonctionné qu'une...  Brumisateur à pompe   \n",
       "1  Si vous voulez être déçu achetez le produit ! ...       Insatisfaisant   \n",
       "2  Écran de mauvaise qualité, car il s'use en peu...    Ne recommande pas   \n",
       "3  Cet engin ne sert à rien les sons sont pourris...            A éviter!   \n",
       "4  Très beau produit mais la grue n'a pas fonctio...                Déçue   \n",
       "\n",
       "  language     product_category  \n",
       "0       fr               beauty  \n",
       "1       fr         baby_product  \n",
       "2       fr                   pc  \n",
       "3       fr  musical_instruments  \n",
       "4       fr                  toy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce dataset regroupe les avis laissés par les acheteurs sur Amazon. Il est intéressant puisque chaque avis est associé à plusieurs catégories, ce qui permet d'utiliser ce dataset pour différents problèmes. Ici, la note laissée par l'acheteur pour un produit est indiquée dans la colonne 'stars' et exprime sa satisfaction quant au produit. \n",
    "\n",
    "Pour résoudre notre problématique d'analyse de sentiments, nous n'allons garder que les colonnes review_body et stars, que nous renommerons 'texts' et 'classes'. Il nous faudra appliquer ce filtre aux trois datasets (train, dev et test). Nous allons donc écrire une fonction pour appliquer le même filtrage facilement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrer et renommer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, list_columns):\n",
    "    \"\"\"\n",
    "    Retourne le DataFrame avec uniquement les colonnes demandées\n",
    "    \"\"\"\n",
    "    filtered_df = df[list_columns]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A déconseiller - Article n'a fonctionné qu'une...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Si vous voulez être déçu achetez le produit ! ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Écran de mauvaise qualité, car il s'use en peu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cet engin ne sert à rien les sons sont pourris...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Très beau produit mais la grue n'a pas fonctio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  stars\n",
       "0  A déconseiller - Article n'a fonctionné qu'une...      1\n",
       "1  Si vous voulez être déçu achetez le produit ! ...      1\n",
       "2  Écran de mauvaise qualité, car il s'use en peu...      1\n",
       "3  Cet engin ne sert à rien les sons sont pourris...      1\n",
       "4  Très beau produit mais la grue n'a pas fonctio...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_col = ['review_body', 'stars'] # liste des colonnes que l'on souhaite garder\n",
    "train = filter_df(trainset, keep_col) \n",
    "dev = filter_df(devset, keep_col)\n",
    "test = filter_df(testset, keep_col)\n",
    "train.head() # on visualise les premieres lignes du df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction pour renommer automatiquement les colonnes de la même façon sur les trois datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, list_rename):\n",
    "    \"\"\"\n",
    "    Retourne un DF avec les noms de colonnes changées par celles de list_rename\n",
    "    \"\"\"\n",
    "    df.columns = list_rename\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A déconseiller - Article n'a fonctionné qu'une...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Si vous voulez être déçu achetez le produit ! ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Écran de mauvaise qualité, car il s'use en peu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cet engin ne sert à rien les sons sont pourris...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Très beau produit mais la grue n'a pas fonctio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  classes\n",
       "0  A déconseiller - Article n'a fonctionné qu'une...        1\n",
       "1  Si vous voulez être déçu achetez le produit ! ...        1\n",
       "2  Écran de mauvaise qualité, car il s'use en peu...        1\n",
       "3  Cet engin ne sert à rien les sons sont pourris...        1\n",
       "4  Très beau produit mais la grue n'a pas fonctio...        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_rename = ['texts', 'classes']\n",
    "train = rename_columns(train, list_rename)\n",
    "dev = rename_columns(dev, list_rename)\n",
    "test = rename_columns(test, list_rename)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des classes\n",
    "\n",
    "Comme on peut le voir ci-dessus, les classes sont déjà sous forme numérique: il n'y a donc pas besoin d'utiliser le ``LabelEncoder`` de ``scikit-learn`` pour transformer les noms des classes. Cependant, il est toujours important de visualiser la distribution des classes, afin de s'assurer que certaines classes soient déséquilibrées:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "Produisez un diagramme à barres pour visualiser la répartition de chaque classes, puis interprétez le résultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.classes.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le diagramme ci-dessus, on constate qu'il y a 40 000 exemples pour chaque classe, ce qui fait qu'elles sont équilibrées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque nous venons d'effectuer un certain nombre d'étapes de prétraitement, et que l'on aura sans doute besoin de réutiliser ces données, nous allons sauvegarder ces trois DataFrame sur le disque afin de pouvoir les charger sans avoir à appliquer de nouveaux ces prétraitements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g9/npfr2mks4118dkv7g8ckgccr0000gn/T/ipykernel_14338/2040141409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/multiclass/as_train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/multiclass/as_dev.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/multiclass/as_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cours/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cours/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cours/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cours/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ici on précise index = None pour éviter que l'index ne soit conservé\n",
    "# comme une colonne du fichier\n",
    "import os\n",
    "\n",
    "if not os.path.exists('data/multiclass'):\n",
    "    os.mkdir('data/multiclass')\n",
    "train.to_csv('data/multiclass/as_train.csv', index = None)\n",
    "dev.to_csv('data/multiclass/as_dev.csv', index = None)\n",
    "test.to_csv('data/multiclass/as_test.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction du nombre de classes\n",
    "\n",
    "La classification multiclasses en TAL peut être une tâche compliquées. A moins d'utiliser des techniques plus avancées, il est difficile d'obtenir de bons résultats lors de l'entraînement. Nous allons donc transformer légèrement ce dataset de telle sorte à n'avoir que deux classes: positif et négatif.\n",
    "\n",
    "Notre dataset est composé de 5 classes: **Très mauvais** (1), **Mauvais** (2), **Neutre** (3), **Bon** (4), **Très bon** (5). Pour le réduire à deux classes nous allons regrouper les classes 1 et 2 dans 'Négatif', les classes 4 et 5 dans 'Positif' et supprimer la classe 3 (étant neutre, on ne peut facilement l'assimiler à l'une des deux autres classes).\n",
    "\n",
    "Pour remplacer un ensemble de données dans un DataFrame, on peut utiliser la fonction ``replace``. Celle-ci prend en entrée une liste de données à remplacer et une liste de même taille des nouvelles données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(df, col, old_data, new_data):\n",
    "    \"\"\"\n",
    "    Remplace old_data par new_data dans colonne col du DataFrame df\n",
    "    \"\"\"\n",
    "    df[col].replace(old_data, new_data, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasgutehrle/opt/anaconda3/envs/cours/lib/python3.9/site-packages/pandas/core/generic.py:6619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A déconseiller - Article n'a fonctionné qu'une...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Si vous voulez être déçu achetez le produit ! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Écran de mauvaise qualité, car il s'use en peu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cet engin ne sert à rien les sons sont pourris...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Très beau produit mais la grue n'a pas fonctio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  classes\n",
       "0  A déconseiller - Article n'a fonctionné qu'une...        0\n",
       "1  Si vous voulez être déçu achetez le produit ! ...        0\n",
       "2  Écran de mauvaise qualité, car il s'use en peu...        0\n",
       "3  Cet engin ne sert à rien les sons sont pourris...        0\n",
       "4  Très beau produit mais la grue n'a pas fonctio...        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data = [1, 2, 4, 5] # classes que l'on souhaite remplacer\n",
    "new_data = [0, 0, 1, 1] # valeurs respectives par lesquelles on remplace\n",
    "\n",
    "bi_train = replace_values(train, 'classes', old_data, new_data)\n",
    "bi_dev = replace_values(dev, 'classes', old_data, new_data)\n",
    "bi_test = replace_values(test, 'classes', old_data, new_data)\n",
    "\n",
    "bi_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_train.classes.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supprimer les valeurs neutres\n",
    "\n",
    "Ci-dessous, on filtre le DataFrame de telle sorte à ne conserver que les lignes pour lesquelles la valeur de 'classes' est tout sauf 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_train = bi_train[bi_train['classes'] != 3]\n",
    "bi_dev = bi_dev[bi_dev['classes'] != 3]\n",
    "bi_test = bi_test[bi_test['classes'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80000\n",
       "1    80000\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_train['classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_train.classes.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nouveau, nous allons sauvegarder sur le disque ces fichiers de telle sorte à pouvoir réutiliser ces données sans effectuer à nouveau les prétraitements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/binary'):\n",
    "    os.mkdir('data/binary')\n",
    "bi_train.to_csv('data/binary/bi_as_train.csv', index = None)\n",
    "bi_dev.to_csv('data/binary/bi_as_dev.csv', index = None)\n",
    "bi_test.to_csv('data/binary/bi_as_test.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Bien que l'analyse de sentiment soit le problème de base pour la classification en TAL, il s'agit en vérité d'un problème loin d'être trivial. Si cette tâche est relativement aisée avec deux classes, il suffit d'en ajouter une troisième (généralement neutre) pour baisser drastiquement les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Comme nous l'avons vu au début de ce cours, chaque dataset est composé de ``samples`` (lignes) et de ``features`` (colonnes). Ces features doivent être au format numérique pour pouvoir être utilisées par les algorithmes. Cependant, notre colonne ``text`` n'est pas en soit une feature puisqu'on ne peut l'utiliser tel quel.  Il faut donc trouver un moyen d'extraire les caractéristiques de cette colonne. En Machine-Learning, cette étape est appelée ``Feature-Extraction``, et est une étape cruciale dans le processus d'entraînement d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "Une des plus simples méthodes de Feature-Extraction pour le texte est la méthode dite du ``Bag-of-Words``. Cette méthode ne s'intéresse qu'aux mots eux-mêmes, sans se préoccuper des paragraphes ou de la syntaxe. Elle consiste pour un ensemble de documents donné à compter le nombre d'occurrences de chaque mot. En se débarassant de la syntaxe ou de l'organisation des textes, on consitue donc un ``sac de mots`` contenant un vocabulaire, c'est-à-dire un ensemble fini de mots. On peut alors représenter chaque document par le nombre d'occurrences de chaque mot qu'il contient.\n",
    "\n",
    "Etablir un sac de mots se réalise en trois étapes:\n",
    "\n",
    "* La tokenization\n",
    "* La constitution du vocabulaire\n",
    "* L'encodage\n",
    "\n",
    "Pour démontrer ces trois étapes, nous allons utiliser le faux corpus ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Un anneau pour les gouverner tous.', \n",
    "          'Un anneau pour les trouver.', \n",
    "          'Un anneau pour les amener tous et dans les ténèbres les lier.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cabkp1w91Ei"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "La tokenization est le processus consistant à transformer une ou plusieurs chaînes de caractères continues en un ensemble d'unités distinctes. L'unité ainsi obtenue est appelée token. Grâce à la tokenization, il devient possible de traitrer indépendemment chaque unité d'un texte, facilitant ainsi leur encodage.\n",
    "\n",
    "Généralement, l'unité choisie est le mot (plus exactement l'unité lexicale), mais on peut également tokenizer à des niveaux plus fins, comme celui des sous-mots ou des caractères.\n",
    "\n",
    "\n",
    "```\n",
    "\"La batterie est arrivée cassée au niveau de la nappe de connexion.\"\n",
    "\n",
    "Mot : ['La', 'batterie', 'est', 'arrivée', 'cassée', 'au', 'niveau', 'de', 'la', 'nappe', 'de', 'connexion']\n",
    "\n",
    "Sous-mot : ['La', 'batterie', 'est', 'arriv', '##ée', 'cass', '##ée', 'au', 'niveau', 'de', 'la', 'nappe', 'de', 'connexion']\n",
    "\n",
    "Caractères : ['L', 'a', 'b', 'a', 't', 't', 'e', 'r', 'i', 'e', ...]\n",
    "\n",
    "```\n",
    "\n",
    "Tokenizer est une tâche loin d'être triviale: on ne peut en effet pas simplement diviser les phrases aux niveaux des espaces seulements. Il suffit de prendre la phrase ci-dessus pour s'en rendre compte:\n",
    "\n",
    "\n",
    "``Y-a-t-il de nouveaux arrivants?``\n",
    "\n",
    "Si l'on divise aux espaces simplements, on obtient ``['Y-a-t-il', 'de', 'nouveaux', 'arrivants?']``. On vient donc bien qu'il y-a au moins trois unités lexicales distinctes dans le premier token, et deux dans le dernier token. Ainsi, tokenizer demande de prendre en compte les différents signes graphiques et les particularités de chaque langues pour être efficace. \n",
    "\n",
    "On reviendra plus en détails sur la tokenization, qui est un sujet d'études à part entière en NLP. Dans l'immédiat et de manière générale, on peut se contenter de tokenizer au niveau des mots. De plus, des outils comme Spacy, OpenNLP ou torchtext proposent des tokenizer très performants. Ainsi, à moins de ne travailler sur une langue ou un problème bien particulier, il est recommandé d'utiliser les outils déjà existants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au vu de la simplicité de notre corpus, nous nous contenterons de tokenizer au niveaux des espaces entre les mots, avec la fonction ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize en splittant le text au niveau des espaces. Retourne une liste.\n",
    "    \"\"\"\n",
    "    split_text = text.split()\n",
    "    \n",
    "    return split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : Un anneau pour les gouverner tous.\n",
      "Split doc : ['Un', 'anneau', 'pour', 'les', 'gouverner', 'tous.']\n",
      "Doc : Un anneau pour les trouver.\n",
      "Split doc : ['Un', 'anneau', 'pour', 'les', 'trouver.']\n",
      "Doc : Un anneau pour les amener tous et dans les ténèbres les lier.\n",
      "Split doc : ['Un', 'anneau', 'pour', 'les', 'amener', 'tous', 'et', 'dans', 'les', 'ténèbres', 'les', 'lier.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = []\n",
    "for doc in corpus: # pour chaque document\n",
    "    print(\"Doc :\", doc)\n",
    "    split_doc = tokenize(doc) # on tokenize le document\n",
    "    print(\"Split doc :\", split_doc)\n",
    "    tokenized_corpus.append(split_doc) # on l'ajoute a la liste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constituer le vocabulaire\n",
    "\n",
    "Un vocabulaire, ou lexique, est un ensemble fini de mots. Ce vocabulaire sera notre véritable sac de mot qui nous servira de référence pour encoder nos documents. \n",
    "\n",
    "Lorsqu'on utilise la méthode de sac de mots, chaque mot du vocabulaire devient une des features que l'on utilise pour entraîner le modèle. Ainsi, si l'on a 40 000 samples dans notre dataset, et que notre vocabulaire contient 10 000 mots, on a donc une matrice de ``(40 000 x 10 000)``.\n",
    "\n",
    "Pour créer ce vocabulaire en Python, il nous suffit d'utiliser le type set() et d'y ajouter chaque mot contenu dans nos documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : {'tous.', 'les', 'pour', 'ténèbres', 'trouver.', 'amener', 'tous', 'dans', 'lier.', 'et', 'Un', 'gouverner', 'anneau'}\n",
      "Taille du vocabulaire : 13\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "for doc in tokenized_corpus:\n",
    "  vocabulary.update(doc)\n",
    "\n",
    "print(\"Vocabulaire :\", vocabulary)\n",
    "print(\"Taille du vocabulaire :\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour simplifier, nous allons créer un DataFrame contenant ce corpus ainsi que ce vocabulaire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage\n",
    "\n",
    "Dans le modèle de sac de mots, l'étape d'encodage va consister à associer une valeur numérique à chaque token contenu dans le document que l'on traite. Cette valeur numérique diffère selon la méthode d'encodage que l'on choisit. Ainsi pour chaque mot du vocabulaire, on peut:\n",
    "\n",
    "1. indiquer si celui-ci est présent (1) ou non (0) dans le document\n",
    "2. indiquer sa fréquence d'apparition, c'est-à-dire combien de fois celui-ci apparaît dans le document\n",
    "3. indiquer son poids par rapport aux documents et aux autre mots du vocabulaire (ce qui correspond à la méthode TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Présence / Abscence du mot (One-Hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : {'tous.', 'les', 'pour', 'ténèbres', 'trouver.', 'amener', 'tous', 'dans', 'lier.', 'et', 'Un', 'gouverner', 'anneau'}\n",
      "Doc : Un anneau pour les gouverner tous.\n",
      "tous. : 1\n",
      "les : 1\n",
      "pour : 1\n",
      "ténèbres : 0\n",
      "trouver. : 0\n",
      "amener : 0\n",
      "tous : 0\n",
      "dans : 0\n",
      "lier. : 0\n",
      "et : 0\n",
      "Un : 1\n",
      "gouverner : 1\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n",
      "Doc : Un anneau pour les trouver.\n",
      "tous. : 0\n",
      "les : 1\n",
      "pour : 1\n",
      "ténèbres : 0\n",
      "trouver. : 1\n",
      "amener : 0\n",
      "tous : 0\n",
      "dans : 0\n",
      "lier. : 0\n",
      "et : 0\n",
      "Un : 1\n",
      "gouverner : 0\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n",
      "Doc : Un anneau pour les amener tous et dans les ténèbres les lier.\n",
      "tous. : 0\n",
      "les : 1\n",
      "pour : 1\n",
      "ténèbres : 1\n",
      "trouver. : 0\n",
      "amener : 1\n",
      "tous : 1\n",
      "dans : 1\n",
      "lier. : 1\n",
      "et : 1\n",
      "Un : 1\n",
      "gouverner : 0\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tous.</th>\n",
       "      <th>les</th>\n",
       "      <th>pour</th>\n",
       "      <th>ténèbres</th>\n",
       "      <th>trouver.</th>\n",
       "      <th>amener</th>\n",
       "      <th>tous</th>\n",
       "      <th>dans</th>\n",
       "      <th>lier.</th>\n",
       "      <th>et</th>\n",
       "      <th>Un</th>\n",
       "      <th>gouverner</th>\n",
       "      <th>anneau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les gouverner tous.</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les trouver.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les amener tous et dans les ténèbres les lier.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tous.  les  pour  \\\n",
       "Un anneau pour les gouverner tous.                      1    1     1   \n",
       "Un anneau pour les trouver.                             0    1     1   \n",
       "Un anneau pour les amener tous et dans les ténè...      0    1     1   \n",
       "\n",
       "                                                    ténèbres  trouver.  \\\n",
       "Un anneau pour les gouverner tous.                         0         0   \n",
       "Un anneau pour les trouver.                                0         1   \n",
       "Un anneau pour les amener tous et dans les ténè...         1         0   \n",
       "\n",
       "                                                    amener  tous  dans  lier.  \\\n",
       "Un anneau pour les gouverner tous.                       0     0     0      0   \n",
       "Un anneau pour les trouver.                              0     0     0      0   \n",
       "Un anneau pour les amener tous et dans les ténè...       1     1     1      1   \n",
       "\n",
       "                                                    et  Un  gouverner  anneau  \n",
       "Un anneau pour les gouverner tous.                   0   1          1       1  \n",
       "Un anneau pour les trouver.                          0   1          0       1  \n",
       "Un anneau pour les amener tous et dans les ténè...   1   1          0       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vocabulaire :\", vocabulary)\n",
    "data = []\n",
    "for i, doc in enumerate(tokenized_corpus):\n",
    "    print(\"Doc :\", \" \".join(doc))\n",
    "    vocab_count = []\n",
    "    for x in vocabulary:\n",
    "        if x in doc:\n",
    "            print(f\"{x} : 1\")\n",
    "            vocab_count.append(1)\n",
    "        else:\n",
    "            print(f\"{x} : 0\")\n",
    "            vocab_count.append(0)\n",
    "    data.append(vocab_count)\n",
    "    print(\"\\n---\\n\")\n",
    "    \n",
    "binary_df = pd.DataFrame(data = data,\n",
    "                        columns = list(vocabulary))\n",
    "binary_df.index = corpus\n",
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Fréquence d'apparition des mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire : {'tous.', 'les', 'pour', 'ténèbres', 'trouver.', 'amener', 'tous', 'dans', 'lier.', 'et', 'Un', 'gouverner', 'anneau'}\n",
      "Doc : Un anneau pour les gouverner tous.\n",
      "tous. : 1\n",
      "les : 1\n",
      "pour : 1\n",
      "ténèbres : 0\n",
      "trouver. : 0\n",
      "amener : 0\n",
      "tous : 0\n",
      "dans : 0\n",
      "lier. : 0\n",
      "et : 0\n",
      "Un : 1\n",
      "gouverner : 1\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n",
      "Doc : Un anneau pour les trouver.\n",
      "tous. : 0\n",
      "les : 1\n",
      "pour : 1\n",
      "ténèbres : 0\n",
      "trouver. : 1\n",
      "amener : 0\n",
      "tous : 0\n",
      "dans : 0\n",
      "lier. : 0\n",
      "et : 0\n",
      "Un : 1\n",
      "gouverner : 0\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n",
      "Doc : Un anneau pour les amener tous et dans les ténèbres les lier.\n",
      "tous. : 0\n",
      "les : 3\n",
      "pour : 1\n",
      "ténèbres : 1\n",
      "trouver. : 0\n",
      "amener : 1\n",
      "tous : 1\n",
      "dans : 1\n",
      "lier. : 1\n",
      "et : 1\n",
      "Un : 1\n",
      "gouverner : 0\n",
      "anneau : 1\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tous.</th>\n",
       "      <th>les</th>\n",
       "      <th>pour</th>\n",
       "      <th>ténèbres</th>\n",
       "      <th>trouver.</th>\n",
       "      <th>amener</th>\n",
       "      <th>tous</th>\n",
       "      <th>dans</th>\n",
       "      <th>lier.</th>\n",
       "      <th>et</th>\n",
       "      <th>Un</th>\n",
       "      <th>gouverner</th>\n",
       "      <th>anneau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les gouverner tous.</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les trouver.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les amener tous et dans les ténèbres les lier.</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tous.  les  pour  \\\n",
       "Un anneau pour les gouverner tous.                      1    1     1   \n",
       "Un anneau pour les trouver.                             0    1     1   \n",
       "Un anneau pour les amener tous et dans les ténè...      0    3     1   \n",
       "\n",
       "                                                    ténèbres  trouver.  \\\n",
       "Un anneau pour les gouverner tous.                         0         0   \n",
       "Un anneau pour les trouver.                                0         1   \n",
       "Un anneau pour les amener tous et dans les ténè...         1         0   \n",
       "\n",
       "                                                    amener  tous  dans  lier.  \\\n",
       "Un anneau pour les gouverner tous.                       0     0     0      0   \n",
       "Un anneau pour les trouver.                              0     0     0      0   \n",
       "Un anneau pour les amener tous et dans les ténè...       1     1     1      1   \n",
       "\n",
       "                                                    et  Un  gouverner  anneau  \n",
       "Un anneau pour les gouverner tous.                   0   1          1       1  \n",
       "Un anneau pour les trouver.                          0   1          0       1  \n",
       "Un anneau pour les amener tous et dans les ténè...   1   1          0       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vocabulaire :\", vocabulary)\n",
    "data = []\n",
    "for i, doc in enumerate(tokenized_corpus):\n",
    "    print(\"Doc :\", \" \".join(doc))\n",
    "    vocab_count = []\n",
    "    for x in vocabulary:\n",
    "        if x in doc:\n",
    "            count = doc.count(x)\n",
    "            print(f\"{x} : {count}\")\n",
    "            vocab_count.append(count)\n",
    "        else:\n",
    "            print(f\"{x} : 0\")\n",
    "            vocab_count.append(0)\n",
    "    data.append(vocab_count)\n",
    "    print(\"\\n---\\n\")\n",
    "    \n",
    "freq_df = pd.DataFrame(data = data,\n",
    "                        columns = list(vocabulary))\n",
    "freq_df.index = corpus\n",
    "freq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "En regardant le vocabulaire ci-dessus, on peut déjà voir les soucis que peut poser une simple tokenization en divisant le texte au niveau des espaces: Ici, on voit les mots ``[lier., trouver., tous.]`` suivis d'un point, alors qu'il ne devrait pas y être. \n",
    "\n",
    "De même, on voit le mot ``Un`` avec une majuscule: ainsi, si l'on avait eu le mot ``un`` sans majuscule, celui-ci aurait compté comme un autre token. Ceci montre l'importance de normaliser sont corpus avant de le tokenizer. Nous reviendrons plus tard sur les différentes méthodes de normalisation.\n",
    "\n",
    "Enfin, on peut voir que les mots les plus fréquents ou qui apparraissent systématiquement dans les trois documents sont des mots vides tels que ``[les, dans, Un, et, pour]``. Ces mots-vides, que l'on appelle également ``stopwords``, sont ceux qui apparaissent le plus fréquemment dans un corpus et donc par conséquent, sont ceux qui apportent le moins d'information (selon la loi de Zipf). Supprimer ces mots-vides du vocabulaire est généralement nécessaire afin d'en réduire la taille et ainsi conserver de l'espace mémoire. Nous reviendrons également sur cette notion plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "Bien que l'on puisse implémenter nous-même les étapes précédentes, cela peut devenir laborieux si l'on répète l'opération régulièrement, sans compter si l'on traite des corpus bien plus grands que notre faux corpus. Ainsi, on peut utiliser l'objet ``CountVectorizer`` de ``scikit-learn`` pour réaliser les mêmes opérations et plus encore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le ``LabelEncoder``, le ``CountVectorizer`` est un transformer: il possède une fonction ``fit()`` lui permettant de s'adapter aux données ainsi qu'une fonction ``transform()`` lui permettant de transformer ces données sous une autre forme. \n",
    "\n",
    "Ici, ``CountVectorizer()`` permet de transformer un corpus de texte en vecteurs d'occurrences de mots, comme nous l'avons fait précédemment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(corpus)\n",
    "X = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 3, 1, 1, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary :  ['amener' 'anneau' 'dans' 'et' 'gouverner' 'les' 'lier' 'pour' 'tous'\n",
      " 'trouver' 'ténèbres' 'un']\n",
      "Matrice d'occurrences :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amener</th>\n",
       "      <th>anneau</th>\n",
       "      <th>dans</th>\n",
       "      <th>et</th>\n",
       "      <th>gouverner</th>\n",
       "      <th>les</th>\n",
       "      <th>lier</th>\n",
       "      <th>pour</th>\n",
       "      <th>tous</th>\n",
       "      <th>trouver</th>\n",
       "      <th>ténèbres</th>\n",
       "      <th>un</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les gouverner tous.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les trouver.</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Un anneau pour les amener tous et dans les ténèbres les lier.</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    amener  anneau  dans  et  \\\n",
       "Un anneau pour les gouverner tous.                       0       1     0   0   \n",
       "Un anneau pour les trouver.                              0       1     0   0   \n",
       "Un anneau pour les amener tous et dans les ténè...       1       1     1   1   \n",
       "\n",
       "                                                    gouverner  les  lier  \\\n",
       "Un anneau pour les gouverner tous.                          1    1     0   \n",
       "Un anneau pour les trouver.                                 0    1     0   \n",
       "Un anneau pour les amener tous et dans les ténè...          0    3     1   \n",
       "\n",
       "                                                    pour  tous  trouver  \\\n",
       "Un anneau pour les gouverner tous.                     1     1        0   \n",
       "Un anneau pour les trouver.                            1     0        1   \n",
       "Un anneau pour les amener tous et dans les ténè...     1     1        0   \n",
       "\n",
       "                                                    ténèbres  un  \n",
       "Un anneau pour les gouverner tous.                         0   1  \n",
       "Un anneau pour les trouver.                                0   1  \n",
       "Un anneau pour les amener tous et dans les ténè...         1   1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)\n",
    "X = vectorizer.transform(corpus)\n",
    "\n",
    "# on peut reduire les deux dernieres lignes en une seule :\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Vocabulary : \", vectorizer.get_feature_names_out())\n",
    "print(\"Matrice d'occurrences :\")\n",
    "# print(X.toarray())\n",
    "\n",
    "vec_df = pd.DataFrame(data = X.toarray(),\n",
    "                        columns = vectorizer.get_feature_names_out())\n",
    "vec_df.index = corpus\n",
    "vec_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Si l'on regarde le vocabulaire plus haut, on peut voir que cette fois, il n'y a pas de point aux mots ``[lier, trouver, tous]``, contrairement à ce que l'on a fait plus haut. De même, le mot ``Un`` apparaît ici en minuscule.\n",
    "\n",
    "``CountVectorizer`` se charge lui-même de la tokenization, pour laquelle il prend en charge certains aspects de prétraitement, comme la suppression des ponctuations ou le passage de l'intégrité du texte en minuscule. Nous verrons plus tard comment adapter ces paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous savons comment encoder des données textuelles en vecteurs, nous pouvons appliquer cette méthode à l'ensemble du ``amazon-reviews`` (train, dev et test sets compris). Pour s'assurer que chaque dataset soit traité de la même façon, nous allons d'abord entraîner le ``CountVectorizer`` puis écrire une fonction permettant de transformer les données de la même manière:\n",
    "\n",
    "### Concaténer les données et entraîner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "data = pd.concat([bi_train['texts'], bi_dev['texts'], \n",
    "                  bi_test['texts']])\n",
    "# fit_transform regroupe les deux étapes fit et transform en une seule\n",
    "vectorizer.fit(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       A déconseiller - Article n'a fonctionné qu'une...\n",
       "1       Si vous voulez être déçu achetez le produit ! ...\n",
       "2       Écran de mauvaise qualité, car il s'use en peu...\n",
       "3       Cet engin ne sert à rien les sons sont pourris...\n",
       "4       Très beau produit mais la grue n'a pas fonctio...\n",
       "                              ...                        \n",
       "4995    Pour le prix ça le fait, bon bracelet de rempl...\n",
       "4996    parfait rien a dire c est comme au cinéma je r...\n",
       "4997    compteur vraiment très bien ........ pour occu...\n",
       "4998    J'ai reçu cette guirlande led dans les temps e...\n",
       "4999                  Excellent produit... (Fait le job).\n",
       "Name: texts, Length: 168000, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forme de la matrice : (160000, 48768)\n",
      "Forme de la matrice : (4000, 48768)\n",
      "Forme de la matrice : (4000, 48768)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train= vectorizer.transform(bi_train['texts'])\n",
    "y_train =  bi_train['classes']\n",
    "print(\"Forme de la matrice :\", X_train.shape)\n",
    "\n",
    "X_dev = vectorizer.transform(bi_dev['texts'])\n",
    "y_dev = bi_dev['classes']\n",
    "print(\"Forme de la matrice :\", X_dev.shape)\n",
    "\n",
    "X_test = vectorizer.transform(bi_test['texts'])\n",
    "y_test = bi_test['classes']\n",
    "print(\"Forme de la matrice :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant utiliser ces données numériques de la même manière que les données que nous avions pour le ``iris-dataset``, et les donner en entrée à un algorithme tel que KNN our LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasgutehrle/opt/anaconda3/envs/cours/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88425"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyqRFCo1hCPQ"
   },
   "source": [
    "### Sauvegarder un modèle\n",
    "\n",
    "Maintenant que nous avons entraîné notre modèle, et que nous pouvons être relativement satisfaits des résultats, il ne nous reste plus qu'à le sauvegarder sur le disque, afin de pouvoir plus tard le charger et l'utiliser dans d'autres programmes. \n",
    "\n",
    "Attention, puisque l'on a également entraîné un ``CountVectorizer`` pour encoder nos documents, il ne faut pas oublier de le sauvegarder également, afin de pouvoir encoder de futures données.\n",
    "\n",
    "Les modèles entraînés avec ``scikit-learn`` peuvent être sauvegardés à l'aide de ``pickle`` ou ``joblib``. ``pickle`` et ``joblib`` sont deux librairies permettant de sauvegarder des données au format binaire sur le disques. Historiquement, joblib** est plus adapté pour sauvegarder de grosses masses de données, même si la différence n'est plus tout à fait vraie aujourd'hui. Cependant, sauvegarder un fichier avec **joblib** est syntaxiquement plus léger qu'avec **pickle**.\n",
    "\n",
    "Voir la documentation de scikit-learn pour plus d'exemples : https://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1829,
     "status": "ok",
     "timestamp": 1594374736952,
     "user": {
      "displayName": "Nicolas Gutehrlé",
      "photoUrl": "",
      "userId": "13449761133402795532"
     },
     "user_tz": -120
    },
    "id": "V3XbLA69Azhz",
    "outputId": "94529ccc-003b-461a-823b-eef83ffb3761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/logreg_model/model.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "save_path = 'data/logreg_model'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "dump(vectorizer, f\"{save_path}/vectorizer.joblib\")\n",
    "dump(lr, f'{save_path}/model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "Feature-extraction ne concerne pas que le traitement des données textuelles: elle concerne le traitement de n'importe quel type de features. On peut ainsi répartir les valeurs d'une colonne en trois colonnes ou à l'inverse, réduire le nombre de colonnes utilisées. A DVLP\n",
    "\n",
    "* https://towardsdatascience.com/feature-extraction-techniques-d619b56e31be"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('cours')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "63d2c08867e999184b706abc1228e6e14a103e818b92fa06feeba82a11accc73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
